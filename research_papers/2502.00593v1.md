# Dominated Novelty Search: Rethinking Local Competition in Quality-Diversity

[Ryan Bahlous-Boldi](https://orcid.org/0000-0002-5789-0492)<sup>‚àó</sup> rbahlousbold@umass.edu University of Massachusetts Amherst Amherst, MA, USA

# [Hannah Janmohamed](https://orcid.org/0000-0001-7997-8455) hannah.janmohamed21@imperial.ac.uk

Imperial College London London, United Kingdom

[Maxence Faldor](https://orcid.org/0000-0003-4743-9494)<sup>‚àó</sup> m.faldor22@imperial.ac.uk Imperial College London London, United Kingdom

## [Lisa Coiffard](https://orcid.org/0009-0009-0557-9318)

lisa.coiffard21@imperial.ac.uk Imperial College London London, United Kingdom

## [Antoine Cully](https://orcid.org/0000-0002-3190-7073) a.cully@imperial.ac.uk Imperial College London London, United Kingdom

[Luca Grillotti](https://orcid.org/0000-0003-4539-8211) luca.grillotti16@imperial.ac.uk Imperial College London London, United Kingdom

[Lee Spector](https://orcid.org/0000-0001-5299-4797) lspector@amherst.edu Amherst College Amherst, MA, USA

<span id="page-0-0"></span>![](_page_0_Figure_11.jpeg)

Figure 1: The MAP-Elites grid is limited by its ability to perform search when the achievable descriptor space a) has a complex topological shape, b) is discontinuous, c) is unbounded or d) is high-dimensional. In response, we propose Dominated Novelty Search, a new local competition strategy for Quality-Diversity optimization.

## Abstract

Quality-Diversity is a family of evolutionary algorithms that generate diverse, high-performing solutions through local competition principles inspired by natural evolution. While research has focused on improving specific aspects of Quality-Diversity algorithms, surprisingly little attention has been paid to investigating alternative formulations of local competition itself ‚Äî the core mechanism distinguishing Quality-Diversity from traditional evolutionary algorithms. Most approaches implement local competition through explicit collection mechanisms like fixed grids or unstructured archives, imposing artificial constraints that require predefined bounds or hard-to-tune parameters. We show that Quality-Diversity methods can be reformulated as Genetic Algorithms where local competition occurs through fitness transformations rather than explicit collection mechanisms. Building on this insight, we introduce Dominated Novelty Search, a Quality-Diversity algorithm that

implements local competition through dynamic fitness transformations, eliminating the need for predefined bounds or parameters. Our experiments show that Dominated Novelty Search significantly outperforms existing approaches across standard Quality-Diversity benchmarks, while maintaining its advantage in challenging scenarios like high-dimensional and unsupervised spaces.

## CCS Concepts

‚Ä¢ Computing methodologies ‚Üí Genetic algorithms.

## Keywords

Genetic Algorithms, Quality-Diversity, Open-endedness

## 1 Introduction

Evolution has created an extraordinary tapestry of life across Earth's biosphere. The human brain itself, with its 86 billion neurons forming trillions of synaptic connections, stands as a testament to the

<sup>‚àó</sup>Both authors contributed equally to this research.

![](_page_1_Figure_0.jpeg)

Figure 2: The descriptor specification problem. When trying to categorize the correct bounds for descriptors in QD optimization, one risks missing out on many quality-diverse solutions.

incredible complexity that can emerge from evolutionary processes. Inspired by these biological principles, Genetic Algorithms [\[16\]](#page-8-0) (GA) harness the core mechanisms of evolution to solve complex optimization problems. GAs iteratively evolve a population of solutions through a process of reproduction, evaluation and selection, over successive generations. However, the selection implemented within GAs typically employs global competition within the population, often leading to convergence toward a single dominant solution that optimizes one specific objective.

This contrasts with natural evolution, where species have evolved to fill diverse environments, with competition occurring primarily between organisms within the same niche [\[6\]](#page-8-1). This local competition allows multiple species to coexist and thrive simultaneously, each adapted to its specific environmental conditions, rather than converging to a single dominant species that would be globally optimal. Inspired by this idea, Quality-Diversity [\[24\]](#page-8-2) (QD) is a family of evolutionary algorithms that harness local competition to evolve populations of diverse and high-performing solutions. In QD algorithms, each solution is characterized by both a fitness value measuring its performance and a descriptor vector capturing meaningful features about the solution. These descriptors embed solutions in a continuous space where distances between solutions can be computed, enabling competition to occur locally between similar solutions rather than globally across the entire population.

MAP-Elites (ME) is a foundational QD algorithm that discretizes the descriptor space into a grid of cells [\[22,](#page-8-3) [26\]](#page-8-4). Each cell maintains at most one solution, and competition occurs only between solutions mapped to the same cell. This grid-based approach provides a simple and effective way to structure local competition through spatial partitioning of the descriptor space. However, this crude discretization comes with several fundamental limitations [\[19,](#page-8-5) [25\]](#page-8-6). First, grid-based approaches require defining the bounds of the descriptor space in advance, which is impractical in some cases. For instance, in unsupervised QD algorithms [\[4\]](#page-8-7), the descriptor space is learned during evolution, making it impossible to know its shape and bounds beforehand (Figure [1](#page-0-0) a). Even with manually defined descriptors, the bounds of the descriptor space must often be determined experimentally, making the application of these algorithms arduous (Figure [1](#page-0-0) c). Second, even when bounds are known, some cells may map to regions of the descriptor space where no

![](_page_1_Figure_5.jpeg)

Figure 3: Scatter Plots of Kheperax ( = 30), a high dimensional domain, where a solution's behavior descriptor is 30 evenly spaced positions throughout the agent's trajectory. Due to this, a MAP-Elites grid would need to be 60 dimensions, with many dimension combinations being infeasible (e.g., being at the bottom left at the first step, and at the top right at the next)

valid solutions can exist, as the reachable descriptor space rarely forms a perfect -dimensional rectangular box (Figure [1](#page-0-0) b). These permanently empty cells waste memory resources, ultimately reducing the effective size of the population. Third, the MAP-Elites grid is known to struggle in high-dimensional spaces (Figure [1](#page-0-0) d). Therefore, the commonly used grid shape rarely matches the natural shape of the solution space.

Quality-Diversity algorithms have explored approaches beyond fixed grid through unstructured archives [\[4,](#page-8-7) [5,](#page-8-8) [20\]](#page-8-9), which implement local competition enforcing a minimum distance threshold between individuals. While this creates dynamic niches that emerge naturally from the population structure rather than being predefined by fixed cells, it introduces its own heuristic through a fixed distance threshold that may not be appropriate across all regions of the descriptor space. This threshold parameter proves particularly challenging to tune, as its optimal value varies significantly across different domains and tasks, leading to the development of complex mitigation strategies such as container size control [\[12\]](#page-8-10).

The limitations of existing QD approaches point to a more fundamental question that remains largely unexplored in the Quality-Diversity literature: how can we design more sophisticated local competition strategies? While considerable research has focused on improving specific aspects of QD algorithms like reproduction [\[8\]](#page-8-11) or robustness [\[9\]](#page-8-12), surprisingly little attention has been paid to investigating alternative formulations of local competition itself. The predominant grid-based competition in MAP-Elites and the distance-threshold approach in unstructured archives represent relatively simple competition rules, and the space of possible local competition strategies remains largely unexplored. This gap in our understanding is particularly significant given that local competition is the core mechanism distinguishing QD from traditional evolutionary algorithms. A deeper investigation of alternative competition strategies could unlock substantial improvements in QD algorithms' ability to generate diverse, high-performing solutions.

In this work, we introduce Dominated Novelty Search, a Quality-Diversity algorithm that addresses these limitations through a novel local competition strategy. Our key insight is that Quality-Diversity

algorithms can be viewed as Genetic Algorithms where local competition occurs through specialized fitness transformations, rather than through explicit collection mechanisms like grids or archives. This perspective differs from the traditional view of QD algorithms as distinct from GAs and enables us to derive new QD algorithms by modifying the local competition rules. Dominated Novelty Search implements a novel competition strategy that dynamically adapts to the shape and structure of the descriptor space, eliminating the need for predefined bounds, grid structures, or fixed distance thresholds. Our approach can serve as a drop-in replacement for the grid mechanism in MAP-Elites, making it compatible with existing QD frameworks. Our experimental results demonstrate that Dominated Novelty Search achieves state-of-the-art performance on standard QD benchmarks while introducing a new perspective on local competition in evolutionary algorithms.

#### 2 Related Work

### 2.1 Local Competition in Genetic Algorithms

Evolution's ability to generate diverse, well-adapted species has inspired numerous approaches in evolutionary computation to maintain population diversity. Early techniques focused on preventing premature convergence through mechanisms like fitness sharing [11], which enforces competition between similar solutions to encourage exploration of distant parts of the search space. Hornby [17] introduced the age-layered population structure where individuals compete only with others of similar genetic age, while Hu et al. [18] introduced hierarchical fair competition to restrict competition to occur between solutions of similar fitness levels.

Several multi-objective and elitist algorithms promote diversity implicitly through their selection mechanisms as a natural consequence of search, rather than through an explicit diversity preservation mechanism. For example, NSGA-II [7] maintains diversity through non-dominated sorting and crowding distance mechanisms, without needing a predefined behavior descriptor. Lexicase selection [15], which filters down individuals based on their performance on a large number of objectives that are considered in a random order, similarly maintains high levels of diversity [1, 14].

A radical departure from these approaches came with Novelty Search [20], which completely abandons the objective function and instead rewards solutions solely for being behaviorally different from their predecessors. By introducing the concept of behavioral distance as a fundamental measure for competition, Novelty Search laid crucial groundwork for new forms of local competition that would later be integrated with objective-based optimization in Quality-Diversity algorithms.

#### 2.2 Quality-Diversity

Quality-Diversity algorithms address the challenge of discovering diverse, high-performing solutions through local competition mechanisms [24]. MAP-Elites [22] formalizes this through a grid-based architecture where solutions compete only within their behavioral cell, maintaining the highest-performing individual in each niche. To enhance scalability in high-dimensional behavior spaces, Centroidal Voronoi Tessellations [26] adaptively partition the space into well-distributed regions. While these approaches prove effective,

particularly in robotics applications, they rely on predefined bounds and potentially arbitrary discretization of the behavior space.

Unstructured archives offer an alternative approach to local competition. Novelty Search with Local Competition [21] and AU-RORA [4, 5] make solutions compete only against their behavioral neighbors through a distance-threshold mechanism. While these methods eliminate the need for predefined cells, they introduce new challenges through fixed distance parameters that require careful tuning and often need complex adaptation mechanisms like container size control [12]. Cluster-Elites [25] attempts to address these limitations by dynamically spreading centroids across the actual shape of the discovered solutions rather than within a predefined hyperrectangle, allowing it to better adapt to non-convex behavioral spaces.

Our method, Dominated Novelty Search, introduces a novel approach to local competition that rewards solutions that either outperform their neighbors or find unique behaviors compared to better-performing solutions. Rather than using spatial partitioning or distance thresholds, Dominated Novelty Search creates an emergent competition structure based on relative solution performance and proximity. This approach naturally adapts to the distribution of solutions without requiring predefined bounds or parameters, making it particularly effective for domains with unknown or complex behavioral spaces.

## 3 Background

## 3.1 Genetic Algorithms

Genetic Algorithms (GAs) implement artificial evolution by maintaining a population of candidate solutions and iteratively selecting the most promising ones [16]. At each generation, GAs create new solutions through reproduction operators like crossover and mutation, evaluate their fitness, and select which solutions survive to the next generation. A common implementation of GAs is outlined in Algorithm 1, though many variants exist in the literature.

#### <span id="page-2-0"></span>Algorithm 1 Genetic Algorithm

**Require:** population size N, reproduction batch size B Initialize population X with fitness f

for each generation do

 $X' \leftarrow \text{REPRODUCTION}(X, f)$   $\Rightarrow$  Generate B offspring  $X \leftarrow \text{CONCAT}(X, X')$   $\Rightarrow$  Add offspring to population  $f \leftarrow \text{EVALUATION}(X)$   $\Rightarrow$  Evaluate fitness  $X \leftarrow \text{SELECTION}(X, f)$   $\Rightarrow$  Keep top-N individuals

The GA maintains a population of N candidate solutions  $\mathbf{X} = (\mathbf{x}_i)_{i=1}^N \in \mathbb{R}^{N \times n}$  and their associated fitness scores  $\mathbf{f} = (f_i)_{i=1}^N \in \mathbb{R}^N$  across generations. In each iteration, the algorithm generates B new solutions  $\mathbf{X}' = \text{reproduction}(\mathbf{X}, \mathbf{f})$  through genetic operators such as crossover and mutation. These newly generated solutions are added into the existing population via  $\text{concat}(\mathbf{X}, \mathbf{X}')$ , resulting in an expanded set of N+B solutions. The generation concludes with the selection operator, which sorts solutions according to their competition fitness  $\mathbf{f}$  and preserves the top-N performers through truncation selection.

#### 3.2 Quality-Diversity

Quality-Diversity algorithms extend traditional evolutionary approaches by simultaneously optimizing both the quality and diversity of solutions. Unlike standard GAs that focus solely on fitness optimization, QD algorithms introduce descriptors that characterize meaningful features of solutions. Each solution in QD is evaluated based on both its performance (fitness) and its characteristics (descriptor), represented by a descriptor vector  $\mathbf{d} \in \mathcal{D} \subset \mathbb{R}^D$ .

QD algorithms evolve a population of N solutions  $\mathbf{X} = (\mathbf{x}_i)_{i=1}^N \in \mathbb{R}^{N \times n}$ , maintaining both fitness values  $\mathbf{f} = (f_i)_{i=1}^N \in \mathbb{R}^N$  and descriptors  $\mathbf{d} = (\mathbf{d}_i)_{i=1}^N$  across generations. This integration of descriptors represents a fundamental shift in evolutionary optimization, as it actively seeks to discover multiple high-performing solutions that exhibit different characteristics. This diversity-aware optimization process has led to several algorithmic variants, each employing different mechanisms to organize and maintain their solution collections. These variants primarily differ in how they structure their populations [5] ‚Äî through grids, archives, or other organizational schemes ‚Äî which we detail in the following sections.

3.2.1 Grid. MAP-Elites [22] is a QD algorithm that performs local competition through discretization of the descriptor space into a grid structure. Each cell in the grid is characterized by a centroid  $c_i$ , forming  $C = (c_i)_{i=1}^N$ . At most one solution can be stored in each cell and competition is restricted to solutions mapped to the same cell [22, 26]. This mechanism ensures selective pressure within each descriptor space partition while maintaining diversity across cells. While grids now commonly use CVT for better scaling [26], we refer to both traditional grids and CVT-based approaches as grid-based methods.

<span id="page-3-2"></span>3.2.2 Unstructured Archive. Quality-Diversity algorithms with unstructured archives [5, 20] extend the original MAP-Elites algorithm, offering a flexible framework for handling unknown descriptor spaces [4, 12]. These archives implement local competition through a minimum distance threshold l between solutions in the descriptor space. For each solution, the algorithm calculates its novelty score as the mean distance to its *k* nearest neighbors in the descriptor space. The selection process then considers both the fitness value and this novelty measure, comparing each solution against its closest neighbors to determine which solutions to retain. This flexibility makes unstructured archives particularly valuable in scenarios where the bounds and topology of the descriptor space are unknown beforehand, such as in unsupervised Quality-Diversity optimization [4, 5, 12]. In the remainder of this paper, as multiple archives are unstructured, we will refer to this specific variant as Threshold-Elites (TE).

3.2.3 Cluster-Elites. Cluster-Elites [25] represents an innovative approach to Quality-Diversity optimization that addresses the limitations of fixed-grid methods while maintaining their structural advantages. Unlike traditional MAP-Elites, which requires predefined bounds for the descriptor space, Cluster-Elites adaptively discovers and organizes the solution space through dynamic centroid allocation. When using this algorithm, the population is divided into two distinct subpopulations: C, which serves as centroids for the CVT grid, and X, containing solutions that undergo local competition

within the CVT grid. A key advantage of this method lies in separating two core objectives: maximizing diversity through strategic centroid selection, while improving solution quality through local competition within grid cells.

#### 4 Method

Quality-Diversity optimization has traditionally relied on explicit mechanisms like archives and grids to maintain diversity. Here, we propose a fundamentally different approach that reformulates these mechanisms through the lens of fitness transformations. In Section 4.1, we reformulate QD algorithms as GAs with local competition, demonstrating how fitness transformations can replace traditional archive or grid-based mechanisms. Subsequently, in Section 4.2, we present a specific instantiation of this framework through a novel fitness transformation that enables effective Quality-Diversity optimization. While we focus on one particular implementation, this framework opens possibilities for exploring alternative competition functions, including learned competition mechanisms ‚Äî though such extensions lie beyond the scope of this work.

# <span id="page-3-0"></span>4.1 Quality-Diversity as a Genetic Algorithm with Local Competition

Traditional Quality-Diversity algorithms typically maintain diversity through explicit collection mechanisms such as grids (ME) or archives (NSLC). We present a novel perspective on Quality-Diversity algorithms by reformulating them as GAs augmented with specialized fitness transformations that implement local competition. This perspective shifts focus from the storage mechanisms to the underlying competition dynamics that drive evolutionary search.

## <span id="page-3-1"></span>Algorithm 2 Quality-Diversity

**Require:** population size *N*, reproduction batch size *B*Initialize population **X** with fitness **f** and descriptors **d for** each generation **do** 

 $\begin{array}{llllllllllllllllllllllllllllllllllll$ 

In this framework, Quality-Diversity algorithms closely mirror the structure of GAs, following the same core operations of reproduction, evaluation, and selection. The key distinction lies in how QD algorithms determine which solutions survive to the next generation. Rather than using raw fitness values directly, QD introduces a *competition* function that transforms these values into *competition fitness* scores:  $\tilde{\mathbf{f}} = \text{Competition}(\mathbf{f}, \mathbf{d})$ . This competition function considers both the raw fitness  $\mathbf{f}$  of solutions and their relative positions in descriptor space  $\mathbf{d}$ , creating competition fitness values  $\tilde{\mathbf{f}}$  that drive selection.

The selection mechanism itself remains identical to traditional GAs ‚Äî solutions are ranked by their competition fitness  $\tilde{\mathbf{f}}$  and truncated to maintain a fixed population size N. However, by incorporating descriptor-space proximity into the competition fitness,

this approach maintains diverse solutions across different niches while driving optimization within each niche. Our reformulation reveals that the fundamental innovation of QD algorithms is not their collection mechanisms (grids, archives) but rather how they transform fitness based on local competition. As shown in Algorithm 2, the only difference from the standard GA (Algorithm 1) is the addition of the competition step that computes  $\tilde{\bf f}$ . This perspective unifies existing QD approaches and suggests that new algorithms can be derived by designing novel competition functions.

This reformulation reveals that existing QD algorithms can be understood as implementing different competition functions. For example, in Sections 4.1.1 and 4.1.2 we show that MAP-Elites and Theshold-Elites can be cast within this framework. Our framework suggests that the space of possible local competition strategies extends far beyond existing approaches. By viewing QD algorithms through the lens of competition functions, we open possibilities for designing novel algorithms that can better capture the nuances of local competition in different domains. This perspective also provides a unified theoretical foundation for understanding and comparing different QD approaches, potentially leading to more effective algorithms for generating diverse, high-performing solutions.

- <span id="page-4-1"></span>4.1.1 *MAP-Elites*. MAP-Elites implements competition through its grid structure, where solutions compete only within their assigned cells. For a population with fitness values  $\mathbf{f}$  and descriptors  $\mathbf{d}$ , the COMPETITION function computes  $\tilde{f}$  as follows:
  - Assignment of individuals to their nearest centroid based on descriptor values, partitioning the population into a grid.
  - (2) Within each cell i, preservation of only the highest-fitness individual k by maintaining its original fitness  $\tilde{f}_k = f_k$ , while eliminating others through  $\tilde{f}_i = -\infty$ , for  $i \neq k$ .
- <span id="page-4-2"></span>4.1.2 Threshold-Elites. In Threshold-Elites, the competition function computes  $\tilde{f}$  as follows:
  - (1) For each solution  $\mathbf{x}_i$ , find its nearest living neighbor  $\mathbf{x}_j$  (where j < i and  $f_j > -\infty$ ).
  - (2) If  $\|\mathbf{d}_i \mathbf{d}_j\| > l$ , then solution i retains its original fitness value:  $\tilde{f}_i = f_i$ .
  - (3) If  $\|\mathbf{d}_i \mathbf{d}_j\| \le l$ , then novelty scores are computed for both solutions. When  $\mathbf{x}_i$  improves upon  $\mathbf{x}_j$  in terms of fitness and novelty, it replaces  $\mathbf{x}_j$  by setting  $(\tilde{f}_i, \tilde{f}_j) = (f_i, -\infty)$ . Otherwise,  $\mathbf{x}_j$  is retained and  $\tilde{f}_i = -\infty$ .

#### <span id="page-4-0"></span>4.2 Dominated Novelty Search

Building on Section 4.1, we introduce Dominated Novelty Search, a Quality-Diversity optimization method that implements a new competition function. Unlike MAP-Elites' rigid grid-based partitioning or Threshold-Elites' fixed distance threshold, our method dynamically adapts to the structure of the solution space through a competition mechanism based on relative distances between solutions of different fitness levels.

The key insight behind Dominated Novelty Search is that solutions should be eliminated from the population if they are both inferior in fitness and behaviorally similar to existing solutions. We formalize this intuition through a competition function that

computes modified fitness values  $\tilde{\mathbf{f}}$  based on how distant solutions are from other better-performing solutions. Given a population with fitness values  $\mathbf{f}=(f_i)_{i=1}^N$  and descriptors  $\mathbf{d}=(\mathbf{d}_i)_{i=1}^N$ , the competition function operates in three steps:

For each solution i, identify all solutions with superior fitness:

$$\mathcal{D}_i = \{j \in \{1, \dots, N\} \mid f_j > f_i\}$$

(2) Compute pairwise distances in descriptor space between the solution *i* and all the fitter solutions:

$$d_{ij} = \|\mathbf{d}_i - \mathbf{d}_j\| \quad \forall j \in \mathcal{D}_i$$

(3) Calculate the competition fitness  $\tilde{f}_i$  as the dominated novelty score ‚Äî the average distance to the k-nearest-fitter solutions:

$$\tilde{f}_i = \begin{cases} \frac{1}{k} \sum_{j \in \mathcal{K}_i} d_{ij} & \text{if } |\mathcal{D}_i| > 0 \\ +\infty & \text{otherwise} \end{cases}$$

where  $K_i$  contains the indices of the k solutions in  $\mathcal{D}_i$  with smallest distances  $d_{ij}$  to solution i. If  $|\mathcal{D}_i| < k$ , we use all available fitter solutions.

This competition mechanism creates two complementary evolutionary pressures: individuals must either improve their fitness or discover distinct behaviors that differ from better-performing solutions. Solutions that have no fitter neighbors ( $\mathcal{D}_i = \emptyset$ ) receive an infinite competition fitness, ensuring their preservation in the population. The parameter k controls the locality of competition by determining how many nearby fitter solutions influence each solution's competition fitness. This competition function is used as part of Algorithm 2, where individuals with above median scores are then selected for reproduction in a GA.

A key advantage of Dominated Novelty Search is that it requires no prior knowledge of descriptor space bounds or structure, as it naturally adapts to the reachable regions of the descriptor space. This property makes our method particularly effective for scenarios where the bounds of valid solutions are unknown or when working with learned descriptors, as we demonstrate in our experimental results (Section 5).

#### <span id="page-4-3"></span>5 Experiments

To validate the effectiveness of Dominated Novelty Search, we perform extensive experimental evaluations across multiple domains and compare against standard QD algorithms. Our experimental investigation addresses three fundamental questions:

- How does Dominated Novelty Search perform compared to established QD algorithms on standard continuous control tasks with well-defined descriptor spaces (Section 5.1.1)?
- Can Dominated Novelty Search effectively handle environments with discontinuous descriptor spaces where traditional grid-based approaches struggle (Section 5.1.2)?
- How well does Dominated Novelty Search scale to highdimensional descriptor spaces where defining explicit bounds becomes impractical (Section 5.1.3)?

Each experiment is repeated 10 times with different seeds. We employ the Mann-Whitney U test coupled with Holm-Bonferroni correction to establish statistical significance across multiple comparisons. Our experiments utilize the JAX framework [2] for efficient

parallel computation and the QDax library [\[3\]](#page-8-21) for QD algorithms. All experiments were conducted on NVIDIA A100 GPUs. We have made our repository available [here.](https://github.com/adaptive-intelligent-robotics/Dominated-Novelty-Search)

## 5.1 Tasks

To evaluate the broad applicability of DNS, we conducted experiments across a diverse set of tasks featuring distinct descriptor space characteristics. Our evaluation spans two main categories of tasks: continuous control locomotion tasks implemented in the Brax physics simulator [\[10\]](#page-8-22), and maze navigation tasks based on the deceptive maze environment originally introduced by Lehman and Stanley [\[20\]](#page-8-9) and reimplemented in JAX by Grillotti and Cully [\[13\]](#page-8-23). Table [1](#page-5-3) summarizes the key properties of each task.

Table 1: Overview of tasks and environments.

<span id="page-5-3"></span>

|                    | Walker                         | Ant          | Ant Blocks                               | Kheperax                                                   |
|--------------------|--------------------------------|--------------|------------------------------------------|------------------------------------------------------------|
|                    |                                |              |                                          |                                                            |
| State              | Joints velocity                |              |                                          | Laser ranges                                               |
| Action             | Joints torque                  |              |                                          | Wheels velocity                                            |
| Desc<br>Desc Space | Feet Contact<br>2<br>[0,<br>1] | [‚àí30,<br>30] | Final position<br>2<br>2<br>[‚àí30,<br>30] | ùëõ points Encoding<br>2<br>10<br>ùëõ<br>( [0,<br>1]<br>R<br>) |

<span id="page-5-0"></span>5.1.1 Walker and Ant. The continuous control locomotion tasks challenge agents to move efficiently. The agent's state space includes the position and orientation of its base and the angular positions and velocities of its joints. The action space consists of continuous torque commands that can be applied to each actuated joint. In the Walker task, a bipedal agent must maximize its forward velocity while minimizing energy consumption. The descriptor space for this task captures the contact patterns between the agent's feet and the ground, measured as the contact rate for each foot. In the Ant task, a quadrupedal agent must minimize energy consumption without any forward velocity reward. In this environment, the descriptor space is defined by the agent's final position, creating a continuous 2D descriptor space.

<span id="page-5-1"></span>5.1.2 Ant Blocks. The Ant Blocks environment extends the base Ant task by introducing static obstacles throughout the environment. As in the base task, the quadrupedal agent must optimize for energy-efficient movement while its final position defines the descriptor space. However, the presence of blocks creates natural barriers in the environment, resulting in a discontinuous descriptor space where certain regions become unreachable.

This discontinuity presents a particular challenge for traditional grid-based approaches like MAP-Elites, which predefine descriptor space bounds and allocate computational resources uniformly across this space. When grid cells are allocated to unreachable regions blocked by obstacles, the effective population size is reduced, potentially limiting the algorithm's ability to discover and maintain diverse solutions in the achievable regions of the descriptor space.

<span id="page-5-2"></span>5.1.3 Kheperax. To evaluate performance in high-dimensional descriptor spaces, we employ the Kheperax environment [\[13\]](#page-8-23), that

requires agents to traverse complex mazes. Unlike traditional maze tasks that only consider the agent's final position, we characterize behavior using the agent's trajectory through the environment. Specifically, we construct a high-dimensional descriptor by sampling the agent's position at regular intervals throughout its movement, creating a comprehensive representation of its navigation strategy. This trajectory-based approach enables a richer analysis of agent behavior but introduces significant computational challenges. The resulting high-dimensional descriptor space makes traditional QD methods less effective due to the curse of dimensionality [\[4\]](#page-8-7). Grid-based approaches particularly struggle, as defining meaningful bounds becomes increasingly difficult with each additional dimension, and the number of cells grows exponentially with the descriptor dimensionality.

By selecting these tasks, we aim to demonstrate DNS's capability to handle environments with continuous, discontinuous, and high-dimensional descriptor spaces, showcasing its robustness and adaptability across various scenarios.

## 5.2 Evaluation Metrics

Metrics. We employ two complementary metrics to evaluate algorithm performance: the Quality-Diversity score (QD score) and coverage. The QD score, a standard metric in QD research, measures the cumulative fitness across all solutions in the population, capturing both the quality of individual solutions and the breadth of behaviors discovered. Coverage quantifies purely the diversity aspect by measuring the proportion of descriptor space niches that contain viable solutions.

Traditional implementations of these metrics assume a structured archive, typically the grid used in MAP-Elites. However, this assumption creates challenges when evaluating algorithms with unstructured populations, where solutions are not explicitly organized into predefined niches. In such cases, direct computation of these metrics could emphasize solution quality at the expense of behavioral diversity, particularly for the QD score which might favor clusters of solutions in high-performing regions.

Projected metrics. To ensure comparability across different methods, especially those without inherent archive structure, we project the individuals onto a predefined grid-based archive, similar to that used by ME, to compute metrics. This approach is similar to a "passive archive" that is often used to compute independent metrics [\[23\]](#page-8-24), but has the archive reset at every logging step (instead of persisting throughout the entire run). By doing this, we can compute a QD score and coverage value that accounts for both the quality and diversity of solutions, enabling a fair comparison between structured and unstructured approaches. To ensure that this grid does not favor the grid-based ME variants, we ensure that we project in a grid with randomized centroids.

## 5.3 Baselines

We evaluate DNS against three established Quality-Diversity algorithms, each representing different approaches to implementing local competition in evolutionary search. We detail these baselines in the next sections.

<span id="page-6-0"></span>![](_page_6_Figure_0.jpeg)

Figure 4: Mujoco Environment Results. Each line represents the mean, with shaded regions representing 95% confidence intervals. These results are aggregated across 10 independent runs. Each column represents an environment, and each row represents a given metric after projection into a random grid.

MAP-Elites. MAP-Elites [\[22\]](#page-8-3) is a foundational QD algorithm that discretizes the descriptor space into a grid, maintaining the highest-performing individual in each cell. For our experiments, we initialize a random grid for ME and project the resulting individuals onto a separate, randomly initialized grid for metric computation at each step. Additionally, we implement an optimistic variant where the same grid serves both search and evaluation, establishing an upper performance bound for grid-based approaches.

Cluster-Elites. Cluster-Elites [\[25\]](#page-8-6) is an algorithm designed to adaptively partition the descriptor space, addressing limitations of fixed-grid methods like ME. It employs a clustering mechanism to dynamically adjust centroids based on the distribution of solutions, and using these centroids as the basis to enable efficient local competition between solutions.

Threshold-Elites. Threshold-Elites employs an unstructured archive (as detailed in Section [3.2.2\)](#page-3-2). This algorithm maintains diversity through a distance threshold parameter , which is specifically tuned for each environment except for the unsupervised maze environment. Appendix [B](#page-9-0) outlines how we tuned this value as well as the values we used. For the unsupervised maze environment, use container size control (CSC) [\[12\]](#page-8-10), which automatically determines the value for . Like our approach, Threshold-Elites implements a local competition mechanism where solutions compete based on their proximity in the descriptor space, eliminating the need for explicit space partitioning. This characteristic makes Threshold-Elites particularly suitable for problems with unbounded descriptor spaces.

## 5.4 Results

In this section, we discuss the results and performance of our approach across three key conditions: 1) when the descriptor space is well defined, 2) when the descriptor space is structured but misaligned with the MAP-Elites grid, and 3) when the descriptor space is unsupervised, as in the latent space of an encoding model.

5.4.1 DNS Outperforms Baselines in Well-Defined Descriptor Spaces. Figure [4](#page-6-0) presents results across Mujoco continuous control environments, where descriptor bounds are well established. DNS consistently outperforms both Threshold-Elites (<10‚àí<sup>9</sup> ) and the cluster-elites population (<10‚àí<sup>9</sup> ) across all three environments in terms of QD score as well as coverage values.

Critically, DNS significantly outperforms MAP-Elites in two of the three domains: Walker and Ant Blocks (<10‚àí<sup>3</sup> ). These domains contain implicit constraints that limit reachable behaviors and therefore constrain the descriptor space. For Walker, certain foot-contact proportions (e.g., (0, 0)) are infeasible. Similarly, in Ant Blocks, obstacles prevent certain regions from being explored, making the MAP-Elites grid inefficient. DNS, in contrast, effectively adapts to these constraints, maintaining high diversity and quality.

In the Ant domain, DNS and MAP-Elites perform competitively. This can be attributed to the environment's well-defined, 2D descriptor space that directly aligns with MAP-Elites' grid. This suggests that while MAP-Elites can be effective in cases where the grid directly aligns with the descriptor space, DNS remains the superior choice when dealing with well-defined but constrained spaces.

<span id="page-7-1"></span>![](_page_7_Figure_0.jpeg)

Figure 5: Kheperax with Varied Descriptor Dimensionality

5.4.2 DNS is Robust to Increasing Descriptor Space Dimensionality. A key challenge in QD optimization is maintaining performance as the dimensionality of the descriptor space increases. To evaluate robustness to increasing descriptor dimensionality, we scale the descriptor space dimensionality in the Kheperax domain by sampling the robot's trajectory into evenly spaced points.

Figure [5](#page-7-1) demonstrates that for all except =2 and =10, DNS significantly outperforms all other baselines (<0.05) in terms of both QD Score and coverage. For =2 and =10, DNS outperforms Cluster-Elites and Threshold-Elites, but not significantly. DNS significantly outperforms MAP-Elites on all environment conditions (<0.05). Unlike MAP-Elites, which suffers from discretization inefficiencies in high-dimensional spaces, DNS effectively adapts to the growing descriptor complexity. As the dimensionality of the descriptor increases, a larger proportion of the grid represents unreachable behavior descriptors, which leads to stunting the discovery of stepping stones that are needed to explore the cells that are truly reachable. DNS, on the other hand, is able to adapt the search to the currently reachable portions of the descriptor space, leading to more effective stepping stone discovery.

<span id="page-7-2"></span>![](_page_7_Figure_4.jpeg)

Figure 6: Kheperax with Unsupervised Behavior Descriptors

5.4.3 DNS is Effective for Unsupervised Descriptors. In environments where descriptor spaces are not predefined, DNS maintains its superior performance. Figure [6](#page-7-2) shows results on a variant of the maze tasks where descriptors are learned as low-dimensional embeddings of the agent's trajectory, following the AURORA algorithm [\[4\]](#page-8-7). DNS significantly outperforms other populations in terms of QD score and coverage (<0.05).

This highlights a fundamental advantage of DNS: it adapts to learned descriptor spaces, which are unbounded and changing throughout the evolutionary process. MAP-Elites, which requires a pre-defined and fixed grid, cannot be applied in this scenario. Furthermore, for our unsupervised Maze environment, Threshold-Elites is dependent on a complex container size control mechanism that adapts a distance parameter [\[12\]](#page-8-10). DNS achieves better performance with a relatively simple adaptation mechanism.

## 6 Conclusion and Discussion

In this work, we introduced DNS, a novel Quality-Diversity algorithm that fundamentally rethinks how local competition is implemented in Quality-Diversity algorithms. By eliminating the need for predefined bounds, grid structures, or fixed distance thresholds, our approach offers a more principled solution to the challenge of maintaining diversity in evolved populations.

The experimental results demonstrate that DNS achieves stateof-the-art performance across standard QD benchmarks, validating its effectiveness as a general-purpose Quality-Diversity algorithm. Specifically,

- (1) In well-defined descriptor spaces, DNS significantly outperforms MAP-Elites, demonstrating its ability to adapt to implicit constraints that limit reachable behaviors (e.g., Walker and Ant Blocks).
- (2) In high-dimensional descriptor spaces, DNS is robust to increasing dimensionality, outperforming all baselines as complexity increases, highlighting its scalability.
- (3) In unsupervised descriptor spaces, DNS significantly outperforms all methods, underscoring its ability to adapt to learned representations without requiring pre-defined bounds.

Beyond raw performance metrics, our approach's key advantage lies in its ability to dynamically adapt to the natural structure of the solution space. This adaptability is particularly valuable in scenarios where the shape and bounds of the descriptor space cannot be known in advance, such as in unsupervised Quality-Diversity algorithms where descriptors are learned during evolution. Furthermore, DNS can serve as a drop-in replacement for grid-based mechanisms, eliminating their inherent limitations while maintaining full compatibility with both supervised and unsupervised QD approaches.

Looking forward, this work opens several promising directions for future research. First, by recasting Quality-Diversity as a genetic algorithm with local competition, we introduce a new theoretical framework where the competition function becomes a flexible, interchangeable component. This perspective allows for the development of novel local competition strategies that could further improve efficiency and effectiveness. Second, this reformulation suggests opportunities for learning optimal competition functions ‚Äî for instance, the competition mechanism could be represented as a neural network and trained to maximize population diversity and performance. As the field continues to evolve, we believe the principles introduced in this work will prove valuable in developing even more sophisticated approaches to generating diverse, high-performing solutions to complex problems.

## References

<span id="page-7-0"></span>[1] Ryan Boldi, Li Ding, and Lee Spector. 2024. Solving Deceptive Problems Without Explicit Diversity Maintenance. In Proceedings of the Genetic and Evolutionary Computation Conference Companion. 171‚Äì174.

- <span id="page-8-20"></span>[2] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. 2018. JAX: composable transformations of Python+NumPy programs. http://github.com/jax-ml/jax
- <span id="page-8-21"></span>[3] Felix Chalumeau, Bryan Lim, Rapha√´l Boige, Maxime Allard, Luca Grillotti, Manon Flageat, Valentin Mac√©, Guillaume Richard, Arthur Flajolet, Thomas Pierrot, and Antoine Cully. 2024. QDax: a library for quality-diversity and population-based algorithms with hardware acceleration. *Journal of Machine Learning Research* 25, 108 (2024), 1‚Äì16. http://jmlr.org/papers/v25/23-1027.html
- <span id="page-8-7"></span>[4] Antoine Cully. 2019. Autonomous skill discovery with quality-diversity and unsupervised descriptors. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO '19). Association for Computing Machinery, New York, NY, USA, 81‚Äì89. doi:10.1145/3321707.3321804
- <span id="page-8-8"></span>[5] Antoine Cully and Yiannis Demiris. 2018. Quality and Diversity Optimization: A Unifying Modular Framework. IEEE Transactions on Evolutionary Computation 22, 2 (2018), 245‚Äì259. doi:10.1109/TEVC.2017.2704781
- <span id="page-8-1"></span>[6] Charles Darwin. 1859. On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life (1 ed.). John Murray, London.
- <span id="page-8-16"></span>[7] Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE transactions on evolutionary computation 6, 2 (2002), 182‚Äì197.
- <span id="page-8-11"></span>[8] Maxence Faldor, F√©lix Chalumeau, Manon Flageat, and Antoine Cully. 2024. Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning. ACM Trans. Evol. Learn. Optim. (Sept. 2024). doi:10.1145/3696426
- <span id="page-8-12"></span>[9] Manon Flageat and Antoine Cully. 2023. Uncertain quality-diversity: evaluation methodology and new methods for quality-diversity in uncertain domains. IEEE Transactions on Evolutionary Computation (2023).
- <span id="page-8-22"></span>[10] C. Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem. 2021. Brax - A Differentiable Physics Engine for Large Scale Rigid Body Simulation. http://github.com/google/brax
- <span id="page-8-13"></span>[11] David E. Goldberg and Jon Richardson. 1987. Genetic Algorithms with Sharing for Multimodal Function Optimization. In Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms. 41‚Äì49.
- <span id="page-8-10"></span>[12] Luca Grillotti and Antoine Cully. 2022. Unsupervised Behavior Discovery With Quality-Diversity Optimization. IEEE Transactions on Evolutionary Computation 26. 6 (2022), 1539‚Äì1552. doi:10.1109/TEVC.2022.3159855
- <span id="page-8-23"></span>[13] Luca Grillotti and Antoine Cully. 2023. Kheperax: a Lightweight JAX-based Robot Control Environment for Benchmarking Quality-Diversity Algorithms. In Proceedings of the Companion Conference on Genetic and Evolutionary Computation (Lisbon, Portugal) (GECCO '23 Companion). Association for Computing Machinery, New York, NY, USA, 2163‚Äì2165. doi:10.1145/3583133.3596387
- <span id="page-8-18"></span>[14] Thomas Helmuth, Nicholas Freitag McPhee, and Lee Spector. 2016. Effects of lexicase and tournament selection on diversity recovery and maintenance. In Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion. 983‚Äì990.
- <span id="page-8-17"></span>[15] Thomas Helmuth, Lee Spector, and James Matheson. 2015. Solving Uncompromising Problems With Lexicase Selection. IEEE Transactions on Evolutionary Computation 19, 5 (Oct. 2015), 630‚Äì643. doi:10.1109/TEVC.2014.2362729
- <span id="page-8-0"></span>[16] John H. Holland. 1992. Genetic Algorithms. Scientific American 267, 1 (1992), 66‚Äì73. http://www.jstor.org/stable/24939139
- <span id="page-8-14"></span>[17] Gregory S. Hornby. 2006. ALPS: the age-layered population structure for reducing the problem of premature convergence. In Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation (Seattle, Washington, USA) (GECCO '06). Association for Computing Machinery, New York, NY, USA, 815‚Äì822. doi:10.1145/1143997.1144142
- <span id="page-8-15"></span>[18] Jianjun Hu, Erik Goodman, Kisung Seo, Zhun Fan, and Rondal Rosenberg. 2005. The Hierarchical Fair Competition (HFC) Framework for Sustainable Evolutionary Algorithms. Evol. Comput. 13, 2 (June 2005), 241‚Äì277. doi:10.1162/1063656054088530
- <span id="page-8-5"></span>[19] Paul Kent, Juergen Branke, Adam Gaier, and Jean-Baptiste Mouret. 2022. A discretization-free metric for assessing quality diversity algorithms. In GECCO '22: Proceedings of the Genetic and Evolutionary Computation Conference Companion. ACM, Massachusetts, Boston, 2131‚Äì2135. doi:10.1145/3520304.3534012.
- <span id="page-8-9"></span>[20] Joel Lehman and Kenneth O. Stanley. 2011. Abandoning Objectives: Evolution Through the Search for Novelty Alone. Evolutionary Computation 19, 2 (June 2011), 189‚Äì223. doi:10.1162/EVCO\_a\_00025
- <span id="page-8-19"></span>[21] Joel Lehman and Kenneth O. Stanley. 2011. Evolving a diversity of virtual creatures through novelty search and local competition. In Proceedings of the 13th annual conference on Genetic and evolutionary computation (GECCO '11). Association for Computing Machinery, New York, NY, USA, 211‚Äì218. doi:10. 1145/2001576.2001606
- <span id="page-8-3"></span>22] Jean-Baptiste Mouret and Jeff Clune. 2015. Illuminating search spaces by mapping elites. doi:10.48550/arXiv.1504.04909 arXiv:1504.04909 [cs].
- <span id="page-8-24"></span>[23] Thomas Pierrot, Guillaume Richard, Karim Beguir, and Antoine Cully. 2022. Multi-objective quality diversity optimization. In Proceedings of the Genetic and Evolutionary Computation Conference. 139‚Äì147.

- <span id="page-8-2"></span>[24] Justin K. Pugh, Lisa B. Soros, and Kenneth O. Stanley. 2016. Quality Diversity: A New Frontier for Evolutionary Computation. Frontiers in Robotics and AI 3 (July 2016). doi:10.3389/frobt.2016.00040 Publisher: Frontiers.
- <span id="page-8-6"></span>[25] Vassilis Vassiliades, Konstantinos Chatzilygeroudis, and Jean-Baptiste Mouret. 2017. A comparison of illumination algorithms in unbounded spaces. In Proceedings of the Genetic and Evolutionary Computation Conference Companion. ACM, Berlin Germany, 1578-1581. doi:10.1145/3067695.3082531
- <span id="page-8-4"></span>[26] Vassilis Vassiliades, Konstantinos Chatzilygeroudis, and Jean-Baptiste Mouret. 2018. Using Centroidal Voronoi Tessellations to Scale Up the Multidimensional Archive of Phenotypic Elites Algorithm. IEEE Transactions on Evolutionary Computation 22, 4 (Aug. 2018), 623‚Äì630. doi:10.1109/TEVC.2017.2735550 Conference Name: IEEE Transactions on Evolutionary Computation.

## Supplementary Materials

## A Ablation: Effect of

We run an additional experiment in order to determine the effect of the parameter on the performance of Dominated Novelty Search. Figure [7](#page-10-0) outlines the results of this experiment. There does not appear to be a significant difference in performance for the values of studied in this work.

## <span id="page-9-0"></span>B -value tuning and parameters

For our Threshold-Elites population runs that don't use container size control (i.e., all experiments except for the unsupervised maze environment), the value of must be carefully selected. For environments with easily characterizable behavior spaces (such as Ant and Walker based environments), the value of is simply picked to coincide with the distance between individuals in a uniformly spread grid. For the unsupervised maze, we choose an -value of 0.2. For the other maze environments, we specifically tune the value for each environmental configuration by running each maze with an -value in range {0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1, 2, 3} and

selecting the best performing configuration. The chosen -values are shown in Table [2.](#page-9-1)

<span id="page-9-1"></span>Table 2: Chosen -values for Threshold-Elites across environments.

| Environment                           | Chosen ùëô-value                   |
|---------------------------------------|----------------------------------|
| Walker                                | ‚àöÔ∏É<br>1<br>1<br>√ó<br>2<br>1024   |
| Ant                                   | ‚àöÔ∏É<br>602<br>1<br>√ó<br>2<br>1024 |
| Ant Blocks                            | ‚àöÔ∏É<br>602<br>1<br>√ó<br>2<br>1024 |
| Maze (ùëõ<br>= 2)                       | 0.01                             |
| Maze (ùëõ<br>= 5)                       | 0.1                              |
| Maze (ùëõ<br>= 10,<br>20,<br>30,<br>40) | 0.5                              |
| Maze (ùëõ<br>= 50)                      | 1                                |
| Maze (ùëõ<br>= 100)                     | 1                                |
| Maze (ùëõ<br>= 1000)                    | 3                                |

Received 29 January 2025; revised 12 March 2009; accepted 5 June 2009

<span id="page-10-0"></span>![](_page_10_Figure_0.jpeg)

Figure 7: Results from varying for Dominated Novelty Search on the Maze ( = 30) environment.
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb51291",
   "metadata": {},
   "source": [
    "# Local Sequential Sanity Check\n",
    "\n",
    "**Purpose**: Test determinism by running the SAME experiment twice sequentially:\n",
    "- DNS_baseline seed=42 (run 1)\n",
    "- DNS_baseline seed=42 (run 2)\n",
    "\n",
    "**Expected**: QD scores should be IDENTICAL if execution is deterministic.\n",
    "\n",
    "- This caused 6-14% divergence even though GA never triggered\n",
    "\n",
    "**Note**: Previous test (baseline vs DNS-GA with g_n=99999) was invalid because:- Different scan state structures affect RNG progression\n",
    "- Different algorithm classes (DominatedNoveltySearch vs DominatedNoveltySearchGA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04508ef4",
   "metadata": {},
   "source": [
    "## STEP 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acef4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Current directory: /Users/briancf/Desktop/source/EvoAlgsAndSwarm/lib-qdax/QDax/examples\n",
      "JAX devices: [CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import functools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from qdax.core.dns_ga import DominatedNoveltySearchGA\n",
    "from qdax.core.dns import DominatedNoveltySearch\n",
    "import qdax.tasks.brax as environments\n",
    "from qdax.tasks.brax.env_creators import scoring_function_brax_envs as scoring_function\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Create experiment logs directory\n",
    "os.makedirs(\"seed_variability_logs\", exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e6083",
   "metadata": {},
   "source": [
    "## Generate Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff749d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SANITY CHECK CONFIGURATION\n",
      "================================================================================\n",
      "Seed: 42\n",
      "Execution: Sequential (local Mac M5)\n",
      "Purpose: Verify determinism with sequential execution\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# For sanity check, only use seed 42\n",
    "SANITY_SEED = 42\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SANITY CHECK CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Seed: {SANITY_SEED}\")\n",
    "print(f\"Execution: Sequential (local Mac M5)\")\n",
    "print(f\"Purpose: Verify determinism with sequential execution\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ed96c",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1db35f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Fixed Parameters:\n",
      "  Environment: ant_omni\n",
      "  Iterations: 800\n",
      "  Batch size: 100\n",
      "  ISO_SIGMA: 0.01\n",
      "  Population: 1024\n",
      "\n",
      "Main Configurations (for full 31-seed study):\n",
      "  • DNS_baseline: No GA\n",
      "  • DNS-GA_g300_gen2: 2 GA calls (every 300 iters, 2 gens)\n",
      "  • DNS-GA_g1000_gen4: 0 GA calls (every 1000 iters, 4 gens)\n",
      "\n",
      "Sanity Check Experiments (seed 42):\n",
      "  Run 1: DNS_baseline, seed=42\n",
      "  Run 2: DNS_baseline, seed=42 (duplicate)\n",
      "  Purpose: Test determinism - same algorithm, same seed, twice\n",
      "  Expected: IDENTICAL QD scores (0.00% difference)\n",
      "  Total: 2 experiments\n",
      "  Estimated time: ~6.6 minutes\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "FIXED_PARAMS = {\n",
    "    'batch_size': 100,\n",
    "    'env_name': 'ant_omni',  # Ant Blocks from DNS paper: obstacles + final xy position\n",
    "    'episode_length': 100,\n",
    "    'num_iterations': 800,\n",
    "    'policy_hidden_layer_sizes': (64, 64),\n",
    "    'population_size': 1024,\n",
    "    'k': 3,\n",
    "    'line_sigma': 0.05,\n",
    "    'iso_sigma': 0.01,  # Best performer from previous experiments\n",
    "}\n",
    "\n",
    "# Main experimental configurations (run with all 31 seeds)\n",
    "MAIN_CONFIGS = [\n",
    "    # Baseline (no GA)\n",
    "    {\n",
    "        'type': 'baseline',\n",
    "        'name': 'DNS_baseline',\n",
    "        'g_n': None,\n",
    "        'num_ga_children': None,\n",
    "        'num_ga_generations': None,\n",
    "    },\n",
    "    # Frequent GA calls (10 times during 3000 iterations)\n",
    "    {\n",
    "        'type': 'dns-ga',\n",
    "        'name': 'DNS-GA_g300_gen2',\n",
    "        'g_n': 300,\n",
    "        'num_ga_children': 2,\n",
    "        'num_ga_generations': 2,\n",
    "    },\n",
    "    # Rare but deep GA calls (3 times during 3000 iterations, seed 42's winner)\n",
    "    {\n",
    "        'type': 'dns-ga',\n",
    "        'name': 'DNS-GA_g1000_gen4',\n",
    "        'g_n': 1000,\n",
    "        'num_ga_children': 2,\n",
    "        'num_ga_generations': 4,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Sanity check seed\n",
    "SANITY_SEED = 42\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFixed Parameters:\")\n",
    "print(f\"  Environment: {FIXED_PARAMS['env_name']}\")\n",
    "print(f\"  Iterations: {FIXED_PARAMS['num_iterations']}\")\n",
    "print(f\"  Batch size: {FIXED_PARAMS['batch_size']}\")\n",
    "print(f\"  ISO_SIGMA: {FIXED_PARAMS['iso_sigma']}\")\n",
    "print(f\"  Population: {FIXED_PARAMS['population_size']}\")\n",
    "\n",
    "print(f\"\\nMain Configurations (for full 31-seed study):\")\n",
    "for config in MAIN_CONFIGS:\n",
    "    if config['type'] == 'baseline':\n",
    "        print(f\"  • {config['name']}: No GA\")\n",
    "    else:\n",
    "        ga_calls = FIXED_PARAMS['num_iterations'] // config['g_n']\n",
    "        print(f\"  • {config['name']}: {ga_calls} GA calls (every {config['g_n']} iters, {config['num_ga_generations']} gens)\")\n",
    "\n",
    "print(f\"\\nSanity Check Experiments (seed {SANITY_SEED}):\")\n",
    "print(f\"  Run 1: {MAIN_CONFIGS[0]['name']}, seed={SANITY_SEED}\")\n",
    "print(f\"  Run 2: {MAIN_CONFIGS[0]['name']}, seed={SANITY_SEED} (duplicate)\")\n",
    "print(f\"  Purpose: Test determinism - same algorithm, same seed, twice\")\n",
    "print(f\"  Expected: IDENTICAL QD scores (0.00% difference)\")\n",
    "print(f\"  Total: 2 experiments\")\n",
    "print(f\"  Estimated time: ~6.6 minutes\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5390bd",
   "metadata": {},
   "source": [
    "## STEP 2: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67d76f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def calculate_ga_overhead_evals(g_n, num_iterations, population_size, num_ga_children, num_ga_generations):\n",
    "    \"\"\"Calculate total evaluations performed by Competition-GA.\"\"\"\n",
    "    if g_n is None or g_n >= num_iterations:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    num_ga_calls = num_iterations // g_n\n",
    "    if num_ga_children == 1:\n",
    "        offspring_per_call = population_size * num_ga_generations\n",
    "    else:\n",
    "        offspring_per_call = population_size * num_ga_children * (num_ga_children**num_ga_generations - 1) // (num_ga_children - 1)\n",
    "    evals_per_ga_call = offspring_per_call\n",
    "    total_ga_evals = num_ga_calls * evals_per_ga_call\n",
    "    return total_ga_evals, num_ga_calls, evals_per_ga_call\n",
    "\n",
    "\n",
    "def setup_environment(env_name, episode_length, policy_hidden_layer_sizes, batch_size, seed):\n",
    "    \"\"\"Initialize environment and policy network.\"\"\"\n",
    "    env = environments.create(env_name, episode_length=episode_length)\n",
    "    reset_fn = jax.jit(env.reset)\n",
    "    key = jax.random.key(seed)\n",
    "    \n",
    "    policy_layer_sizes = policy_hidden_layer_sizes + (env.action_size,)\n",
    "    policy_network = MLP(\n",
    "        layer_sizes=policy_layer_sizes,\n",
    "        kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "        final_activation=jnp.tanh,\n",
    "    )\n",
    "    \n",
    "    key, subkey = jax.random.split(key)\n",
    "    keys = jax.random.split(subkey, num=batch_size)\n",
    "    fake_batch = jnp.zeros(shape=(batch_size, env.observation_size))\n",
    "    init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "    \n",
    "    return env, policy_network, reset_fn, init_variables, key\n",
    "\n",
    "\n",
    "def create_scoring_function(env, policy_network, reset_fn, episode_length, env_name):\n",
    "    \"\"\"Create scoring function for fitness evaluation.\"\"\"\n",
    "    def play_step_fn(env_state, policy_params, key):\n",
    "        actions = policy_network.apply(policy_params, env_state.obs)\n",
    "        state_desc = env_state.info[\"state_descriptor\"]\n",
    "        next_state = env.step(env_state, actions)\n",
    "        \n",
    "        transition = QDTransition(\n",
    "            obs=env_state.obs,\n",
    "            next_obs=next_state.obs,\n",
    "            rewards=next_state.reward,\n",
    "            dones=next_state.done,\n",
    "            actions=actions,\n",
    "            truncations=next_state.info[\"truncation\"],\n",
    "            state_desc=state_desc,\n",
    "            next_state_desc=next_state.info[\"state_descriptor\"],\n",
    "        )\n",
    "        return next_state, policy_params, key, transition\n",
    "    \n",
    "    descriptor_extraction_fn = environments.descriptor_extractor[env_name]\n",
    "    scoring_fn = functools.partial(\n",
    "        scoring_function,\n",
    "        episode_length=episode_length,\n",
    "        play_reset_fn=reset_fn,\n",
    "        play_step_fn=play_step_fn,\n",
    "        descriptor_extractor=descriptor_extraction_fn,\n",
    "    )\n",
    "    \n",
    "    return scoring_fn\n",
    "\n",
    "\n",
    "def create_mutation_function(iso_sigma):\n",
    "    \"\"\"Create mutation function for Competition-GA.\"\"\"\n",
    "    def competition_ga_mutation_fn(genotype, key):\n",
    "        genotype_flat, tree_def = jax.tree_util.tree_flatten(genotype)\n",
    "        num_leaves = len(genotype_flat)\n",
    "        keys = jax.random.split(key, num_leaves)\n",
    "        keys_tree = jax.tree_util.tree_unflatten(tree_def, keys)\n",
    "        \n",
    "        def add_noise(x, k):\n",
    "            return x + jax.random.normal(k, shape=x.shape) * iso_sigma\n",
    "        \n",
    "        mutated = jax.tree_util.tree_map(add_noise, genotype, keys_tree)\n",
    "        return mutated\n",
    "    \n",
    "    return competition_ga_mutation_fn\n",
    "\n",
    "print(\"Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77ea26",
   "metadata": {},
   "source": [
    "## STEP 3: Experiment Runner Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f8e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions ready!\n"
     ]
    }
   ],
   "source": [
    "def run_single_experiment(config, seed, fixed_params):\n",
    "    \"\"\"Run a single experiment with given config and seed.\"\"\"\n",
    "    exp_name = f\"{config['name']}_seed{seed}\"\n",
    "    \n",
    "    # Setup environment\n",
    "    env, policy_network, reset_fn, init_variables, key = setup_environment(\n",
    "        fixed_params['env_name'],\n",
    "        fixed_params['episode_length'],\n",
    "        fixed_params['policy_hidden_layer_sizes'],\n",
    "        fixed_params['batch_size'],\n",
    "        seed\n",
    "    )\n",
    "    \n",
    "    scoring_fn = create_scoring_function(env, policy_network, reset_fn, \n",
    "                                        fixed_params['episode_length'],\n",
    "                                        fixed_params['env_name'])\n",
    "    \n",
    "    reward_offset = environments.reward_offset[fixed_params['env_name']]\n",
    "    metrics_function = functools.partial(\n",
    "        default_qd_metrics,\n",
    "        qd_offset=reward_offset * fixed_params['episode_length'],\n",
    "    )\n",
    "    \n",
    "    # Create emitter\n",
    "    variation_fn = functools.partial(\n",
    "        isoline_variation,\n",
    "        iso_sigma=fixed_params['iso_sigma'],\n",
    "        line_sigma=fixed_params['line_sigma']\n",
    "    )\n",
    "    \n",
    "    mixing_emitter = MixingEmitter(\n",
    "        mutation_fn=None,\n",
    "        variation_fn=variation_fn,\n",
    "        variation_percentage=1.0,\n",
    "        batch_size=fixed_params['batch_size']\n",
    "    )\n",
    "    \n",
    "    # Create algorithm (DNS or DNS-GA)\n",
    "    if config['type'] == 'baseline':\n",
    "        algorithm = DominatedNoveltySearch(\n",
    "            scoring_function=scoring_fn,\n",
    "            emitter=mixing_emitter,\n",
    "            metrics_function=metrics_function,\n",
    "            population_size=fixed_params['population_size'],\n",
    "            k=fixed_params['k'],\n",
    "        )\n",
    "    else:\n",
    "        mutation_fn = create_mutation_function(fixed_params['iso_sigma'])\n",
    "        algorithm = DominatedNoveltySearchGA(\n",
    "            scoring_function=scoring_fn,\n",
    "            emitter=mixing_emitter,\n",
    "            metrics_function=metrics_function,\n",
    "            population_size=fixed_params['population_size'],\n",
    "            k=fixed_params['k'],\n",
    "            g_n=config['g_n'],\n",
    "            num_ga_children=config['num_ga_children'],\n",
    "            num_ga_generations=config['num_ga_generations'],\n",
    "            mutation_fn=mutation_fn,\n",
    "        )\n",
    "    \n",
    "    # Initialize\n",
    "    key, subkey = jax.random.split(key)\n",
    "    repertoire, emitter_state, init_metrics = algorithm.init(init_variables, subkey)\n",
    "    \n",
    "    # Setup logging\n",
    "    log_period = 100\n",
    "    num_loops = fixed_params['num_iterations'] // log_period\n",
    "    \n",
    "    metrics = {key: jnp.array([]) for key in [\"iteration\", \"qd_score\", \"coverage\", \"max_fitness\", \"time\"]}\n",
    "    init_metrics = jax.tree.map(lambda x: jnp.array([x]) if x.shape == () else x, init_metrics)\n",
    "    init_metrics[\"iteration\"] = jnp.array([0], dtype=jnp.int32)\n",
    "    init_metrics[\"time\"] = jnp.array([0.0])\n",
    "    metrics = jax.tree.map(\n",
    "        lambda metric, init_metric: jnp.concatenate([metric, init_metric], axis=0),\n",
    "        metrics, init_metrics\n",
    "    )\n",
    "    \n",
    "    log_filename = os.path.join(\"seed_variability_logs\", f\"{exp_name}_logs.csv\")\n",
    "    csv_logger = CSVLogger(log_filename, header=list(metrics.keys()))\n",
    "    csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "    \n",
    "    # Main training loop\n",
    "    if config['type'] == 'baseline':\n",
    "        algorithm_scan_update = algorithm.scan_update\n",
    "        scan_state = (repertoire, emitter_state, key)\n",
    "    else:\n",
    "        algorithm_scan_update = algorithm.scan_update\n",
    "        scan_state = (repertoire, emitter_state, key, 1)  # generation_counter\n",
    "    \n",
    "    start_time_total = time.time()\n",
    "    \n",
    "    for i in range(num_loops):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        scan_state, current_metrics = jax.lax.scan(\n",
    "            algorithm_scan_update,\n",
    "            scan_state,\n",
    "            (),\n",
    "            length=log_period,\n",
    "        )\n",
    "        \n",
    "        timelapse = time.time() - start_time\n",
    "        \n",
    "        current_metrics[\"iteration\"] = jnp.arange(\n",
    "            1 + log_period * i, 1 + log_period * (i + 1), dtype=jnp.int32\n",
    "        )\n",
    "        current_metrics[\"time\"] = jnp.repeat(timelapse, log_period)\n",
    "        metrics = jax.tree.map(\n",
    "            lambda metric, current_metric: jnp.concatenate([metric, current_metric], axis=0),\n",
    "            metrics, current_metrics\n",
    "        )\n",
    "        \n",
    "        csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "    \n",
    "    total_time = time.time() - start_time_total\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ga_total_evals, ga_num_calls, ga_evals_per_call = calculate_ga_overhead_evals(\n",
    "        config.get('g_n'), fixed_params['num_iterations'], fixed_params['population_size'],\n",
    "        config.get('num_ga_children'), config.get('num_ga_generations')\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'config_name': config['name'],\n",
    "        'config_type': config['type'],\n",
    "        'seed': seed,\n",
    "        'g_n': config.get('g_n'),\n",
    "        'num_ga_generations': config.get('num_ga_generations'),\n",
    "        'final_qd_score': float(metrics['qd_score'][-1]),\n",
    "        'final_max_fitness': float(metrics['max_fitness'][-1]),\n",
    "        'final_coverage': float(metrics['coverage'][-1]),\n",
    "        'total_time': total_time,\n",
    "        'ga_overhead_evals': ga_total_evals,\n",
    "        'log_file': log_filename,\n",
    "    }\n",
    "\n",
    "print(\"Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f11a8",
   "metadata": {},
   "source": [
    "## STEP 4: Build Experiment Queue and Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92f08cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SANITY CHECK QUEUE - 20251115_220252\n",
      "================================================================================\n",
      "\n",
      "Determinism Test:\n",
      "  1. DNS_baseline, seed=42\n",
      "  2. DNS_baseline, seed=42\n",
      "\n",
      "Total: 2 experiments\n",
      "Execution: Sequential\n",
      "Estimated time: ~6.6 minutes\n",
      "\n",
      "⚠️  These should have IDENTICAL final QD scores\n",
      "   Any difference indicates non-deterministic execution\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Build sanity check queue (baseline run twice)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"SANITY CHECK QUEUE - {timestamp}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "experiment_queue = []\n",
    "\n",
    "# Run baseline twice with same seed to test determinism\n",
    "baseline_config = [c for c in MAIN_CONFIGS if c['type'] == 'baseline'][0]\n",
    "experiment_queue.append((1, 1, baseline_config, SANITY_SEED))\n",
    "experiment_queue.append((2, 2, baseline_config, SANITY_SEED))\n",
    "\n",
    "print(f\"\\nDeterminism Test:\")\n",
    "for exp_num, _, config, seed in experiment_queue:\n",
    "    print(f\"  {exp_num}. {config['name']}, seed={seed}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(experiment_queue)} experiments\")\n",
    "print(f\"Execution: Sequential\")\n",
    "print(f\"Estimated time: ~{len(experiment_queue) * 3.3:.1f} minutes\")\n",
    "print(f\"\\n⚠️  These should have IDENTICAL final QD scores\")\n",
    "print(f\"   Any difference indicates non-deterministic execution\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db024292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING SANITY CHECK EXPERIMENTS SEQUENTIALLY\n",
      "================================================================================\n",
      "Start time: 2025-11-15 22:02:52\n",
      "Total experiments: 2\n",
      "Estimated time: ~6.6 minutes\n",
      "================================================================================\n",
      "\n",
      "[1/2] Starting: DNS_baseline, seed=42\n",
      "  ✓ Completed in 3.1m: QD=303,592.9\n",
      "\n",
      "[2/2] Starting: DNS_baseline, seed=42\n",
      "  ✓ Completed in 3.1m: QD=303,592.9\n",
      "\n",
      "[2/2] Starting: DNS_baseline, seed=42\n",
      "  ✓ Completed in 3.1m: QD=303,592.9\n",
      "\n",
      "================================================================================\n",
      "SANITY CHECK COMPLETE\n",
      "================================================================================\n",
      "End time: 2025-11-15 22:09:05\n",
      "Total time: 6.2 minutes\n",
      "Successful: 2/2\n",
      "Failed: 0\n",
      "\n",
      "Results saved to: seed_variability_logs/sanity_check_results_20251115_220252.json\n",
      "================================================================================\n",
      "  ✓ Completed in 3.1m: QD=303,592.9\n",
      "\n",
      "================================================================================\n",
      "SANITY CHECK COMPLETE\n",
      "================================================================================\n",
      "End time: 2025-11-15 22:09:05\n",
      "Total time: 6.2 minutes\n",
      "Successful: 2/2\n",
      "Failed: 0\n",
      "\n",
      "Results saved to: seed_variability_logs/sanity_check_results_20251115_220252.json\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Run Sanity Check Experiments Sequentially\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING SANITY CHECK EXPERIMENTS SEQUENTIALLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total experiments: {len(experiment_queue)}\")\n",
    "print(f\"Estimated time: ~{len(experiment_queue) * 3.3:.1f} minutes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time_all = time.time()\n",
    "\n",
    "all_results = []\n",
    "errors = []\n",
    "\n",
    "for exp_num, (_, _, config, seed) in enumerate(experiment_queue, 1):\n",
    "    exp_start = time.time()\n",
    "    config_name = config['name']\n",
    "    \n",
    "    print(f\"\\n[{exp_num}/{len(experiment_queue)}] Starting: {config_name}, seed={seed}\")\n",
    "    \n",
    "    try:\n",
    "        result = run_single_experiment(config, seed, FIXED_PARAMS)\n",
    "        result['exp_num'] = exp_num\n",
    "        all_results.append(result)\n",
    "        \n",
    "        exp_time = time.time() - exp_start\n",
    "        qd = result['final_qd_score']\n",
    "        print(f\"  ✓ Completed in {exp_time/60:.1f}m: QD={qd:,.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'config_name': config_name, 'seed': seed, 'error': str(e)})\n",
    "        print(f\"  ✗ Failed: {str(e)}\")\n",
    "\n",
    "total_time = time.time() - start_time_all\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SANITY CHECK COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total time: {total_time / 60:.1f} minutes\")\n",
    "print(f\"Successful: {len(all_results)}/{len(experiment_queue)}\")\n",
    "print(f\"Failed: {len(errors)}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nErrors encountered:\")\n",
    "    for error in errors:\n",
    "        print(f\"  • {error['config_name']}, seed={error['seed']}: {error['error']}\")\n",
    "\n",
    "# Save results\n",
    "results_file = f\"seed_variability_logs/sanity_check_results_{timestamp}.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'results': all_results,\n",
    "        'errors': errors,\n",
    "        'total_time': total_time,\n",
    "        'timestamp': timestamp,\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: {results_file}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a8877",
   "metadata": {},
   "source": [
    "## STEP 5: Determinism Validation\n",
    "\n",
    "**CRITICAL**: Check if two identical runs produce identical results\n",
    "\n",
    "This validates that the platform can produce reproducible results for seed comparison studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5da91876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DETERMINISM TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "Run 1: DNS_baseline seed=42\n",
      "  Final QD score: 303,592.9\n",
      "\n",
      "Run 2: DNS_baseline seed=42\n",
      "  Final QD score: 303,592.9\n",
      "\n",
      "Absolute difference: 0.000000\n",
      "Percentage difference: 0.000000%\n",
      "\n",
      "✅ PERFECT: Execution is FULLY deterministic\n",
      "  Identical QD scores (0.00% difference)\n",
      "\n",
      "✅ Safe to proceed with full experiments on this machine\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare final QD scores from two identical runs\n",
    "print(\"=\"*80)\n",
    "print(\"DETERMINISM TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(all_results) == 2:\n",
    "    run1 = all_results[0]\n",
    "    run2 = all_results[1]\n",
    "    \n",
    "    qd1 = run1['final_qd_score']\n",
    "    qd2 = run2['final_qd_score']\n",
    "    \n",
    "    diff_abs = abs(qd1 - qd2)\n",
    "    diff_pct = diff_abs / qd1 * 100 if qd1 != 0 else 0\n",
    "    \n",
    "    print(f\"\\nRun 1: {run1['config_name']} seed={run1['seed']}\")\n",
    "    print(f\"  Final QD score: {qd1:,.1f}\")\n",
    "    print(f\"\\nRun 2: {run2['config_name']} seed={run2['seed']}\")\n",
    "    print(f\"  Final QD score: {qd2:,.1f}\")\n",
    "    \n",
    "    print(f\"\\nAbsolute difference: {diff_abs:,.6f}\")\n",
    "    print(f\"Percentage difference: {diff_pct:.6f}%\")\n",
    "    \n",
    "    if diff_abs == 0.0:\n",
    "        print(f\"\\n✅ PERFECT: Execution is FULLY deterministic\")\n",
    "        print(f\"  Identical QD scores (0.00% difference)\")\n",
    "        print(f\"\\n✅ Safe to proceed with full experiments on this machine\")\n",
    "    elif diff_pct < 0.01:\n",
    "        print(f\"\\n✅ PASS: Execution is deterministic (floating-point precision)\")\n",
    "        print(f\"  Difference {diff_pct:.6f}% is negligible\")\n",
    "        print(f\"\\n✅ Safe to proceed with full experiments on this machine\")\n",
    "    elif diff_pct < 2.0:\n",
    "        print(f\"\\n⚠️  ACCEPTABLE: Small variation ({diff_pct:.2f}%)\")\n",
    "        print(f\"  Likely due to numerical precision differences\")\n",
    "        print(f\"  Consider acceptable for stochastic QD algorithms\")\n",
    "    else:\n",
    "        print(f\"\\n❌ FAIL: Execution is NOT deterministic\")\n",
    "        print(f\"  {diff_pct:.2f}% difference is too large for identical runs\")\n",
    "        print(f\"\\n⚠️  WARNING: Platform-specific non-determinism detected\")\n",
    "        print(f\"\\nPossible causes:\")\n",
    "        print(f\"  • Apple Silicon (ARM) vs x86 numerical differences\")\n",
    "        print(f\"  • Metal backend vs CUDA floating-point handling\")\n",
    "        print(f\"  • JAX compilation or random state management\")\n",
    "        print(f\"\\nRECOMMENDATION:\")\n",
    "        print(f\"  • Use Google Colab (x86/CUDA) for final experiments\")\n",
    "        print(f\"  • Or switch to walker2d_uni (proven deterministic on Mac M5)\")\n",
    "        print(f\"  • Current results from this machine cannot be trusted for seed comparisons\")\n",
    "else:\n",
    "    print(f\"\\n❌ ERROR: Expected 2 results, got {len(all_results)}\")\n",
    "    print(f\"Cannot perform determinism validation\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68a03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975f8a74",
   "metadata": {},
   "source": [
    "## STEP 6: Statistical Power Analysis\n",
    "\n",
    "**Purpose**: Estimate baseline variance and determine if 31 seeds is sufficient to detect DNS-GA improvements\n",
    "\n",
    "This analysis will show:\n",
    "- Expected coefficient of variation (CV) for baseline across seeds\n",
    "- Minimum detectable effect size with 31 seeds\n",
    "- Statistical power for detecting 3%, 5%, 10%, and 53% improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0857ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATISTICAL POWER ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Baseline QD Score: 303,592.9\n",
      "Sample Size: 31 seeds\n",
      "\n",
      "Analyzing different variance scenarios:\n",
      "================================================================================\n",
      "\n",
      "Low variance (CV=5%, typical for well-controlled QD)\n",
      "  Standard Deviation: 15,179.6\n",
      "  95% CI width: ±5,343.6\n",
      "\n",
      "  Statistical Power (α=0.05, paired t-test):\n",
      "  Effect          Detectable?     Power      Min Samples    \n",
      "  --------------- --------------- ---------- ---------------\n",
      "    3% improvement ✅ Yes           89.83%    24\n",
      "    5% improvement ✅ Yes           99.97%    10\n",
      "   10% improvement ❌ No            nan%    10\n",
      "   53% improvement ✅ Yes           100.00%    10\n",
      "\n",
      "Medium variance (CV=10%, common for stochastic QD)\n",
      "  Standard Deviation: 30,359.3\n",
      "  95% CI width: ±10,687.3\n",
      "\n",
      "  Statistical Power (α=0.05, paired t-test):\n",
      "  Effect          Detectable?     Power      Min Samples    \n",
      "  --------------- --------------- ---------- ---------------\n",
      "    3% improvement ❌ No            36.60%    90\n",
      "    5% improvement ⚠️  Marginal    76.85%    34\n",
      "   10% improvement ✅ Yes           99.97%    10\n",
      "   53% improvement ✅ Yes           100.00%    10\n",
      "\n",
      "High variance (CV=15%, challenging environment)\n",
      "  Standard Deviation: 45,538.9\n",
      "  95% CI width: ±16,030.9\n",
      "\n",
      "  Statistical Power (α=0.05, paired t-test):\n",
      "  Effect          Detectable?     Power      Min Samples    \n",
      "  --------------- --------------- ---------- ---------------\n",
      "    3% improvement ❌ No            19.01%    199\n",
      "    5% improvement ❌ No            43.51%    73\n",
      "   10% improvement ✅ Yes           94.85%    20\n",
      "   53% improvement ✅ Yes           100.00%    10\n",
      "\n",
      "Very high variance (CV=20%, highly stochastic)\n",
      "  Standard Deviation: 60,718.6\n",
      "  95% CI width: ±21,374.5\n",
      "\n",
      "  Statistical Power (α=0.05, paired t-test):\n",
      "  Effect          Detectable?     Power      Min Samples    \n",
      "  --------------- --------------- ---------- ---------------\n",
      "    3% improvement ❌ No            12.76%    351\n",
      "    5% improvement ❌ No            27.06%    128\n",
      "   10% improvement ⚠️  Marginal    76.85%    34\n",
      "   53% improvement ❌ No            nan%    10\n",
      "\n",
      "================================================================================\n",
      "INTERPRETATION:\n",
      "================================================================================\n",
      "\n",
      "1. **If baseline CV ≤ 10%**: 31 seeds can reliably detect improvements ≥5%\n",
      "   - Your 53% evaluation savings would be easily detected\n",
      "   - Even modest 3-5% improvements would show with good power\n",
      "\n",
      "2. **If baseline CV = 15%**: 31 seeds can detect improvements ≥10%\n",
      "   - Your 53% savings would still be very clear\n",
      "   - Smaller 3-5% effects might need more seeds\n",
      "\n",
      "3. **If baseline CV ≥ 20%**: May need more seeds for small effects\n",
      "   - But 53% improvement would still be detectable\n",
      "   - Consider increasing to 50+ seeds if variance is very high\n",
      "\n",
      "4. **Recommendation**: \n",
      "   - Run 3-5 baseline seeds first to estimate actual CV\n",
      "   - If CV < 15%, proceed with 31 seeds\n",
      "   - If CV > 15%, consider expanding to 50 seeds for better power\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Statistical Power Analysis for 31-Seed Study\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL POWER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Estimate baseline variance from literature/previous experiments\n",
    "# For QD algorithms, typical CV (coefficient of variation) ranges from 5-20%\n",
    "# We'll test different scenarios\n",
    "\n",
    "baseline_mean = 303592.9  # From our determinism test\n",
    "sample_size = 31  # Number of seeds\n",
    "\n",
    "print(f\"\\nBaseline QD Score: {baseline_mean:,.1f}\")\n",
    "print(f\"Sample Size: {sample_size} seeds\")\n",
    "print(f\"\\nAnalyzing different variance scenarios:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cv_scenarios = [\n",
    "    (0.05, \"Low variance (CV=5%, typical for well-controlled QD)\"),\n",
    "    (0.10, \"Medium variance (CV=10%, common for stochastic QD)\"),\n",
    "    (0.15, \"High variance (CV=15%, challenging environment)\"),\n",
    "    (0.20, \"Very high variance (CV=20%, highly stochastic)\"),\n",
    "]\n",
    "\n",
    "for cv, description in cv_scenarios:\n",
    "    baseline_std = baseline_mean * cv\n",
    "    \n",
    "    print(f\"\\n{description}\")\n",
    "    print(f\"  Standard Deviation: {baseline_std:,.1f}\")\n",
    "    print(f\"  95% CI width: ±{1.96 * baseline_std / np.sqrt(sample_size):,.1f}\")\n",
    "    \n",
    "    # Calculate statistical power for different effect sizes\n",
    "    # Using paired t-test (same seed for baseline vs DNS-GA)\n",
    "    alpha = 0.05  # Significance level\n",
    "    \n",
    "    print(f\"\\n  Statistical Power (α={alpha}, paired t-test):\")\n",
    "    print(f\"  {'Effect':<15} {'Detectable?':<15} {'Power':<10} {'Min Samples':<15}\")\n",
    "    print(f\"  {'-'*15} {'-'*15} {'-'*10} {'-'*15}\")\n",
    "    \n",
    "    for effect_pct in [3, 5, 10, 53]:\n",
    "        effect_size = baseline_mean * (effect_pct / 100)\n",
    "        \n",
    "        # Cohen's d for paired samples\n",
    "        cohen_d = effect_size / baseline_std\n",
    "        \n",
    "        # Power calculation for paired t-test\n",
    "        from scipy.stats import nct\n",
    "        df = sample_size - 1\n",
    "        ncp = cohen_d * np.sqrt(sample_size)  # Non-centrality parameter\n",
    "        t_crit = scipy_stats.t.ppf(1 - alpha/2, df)\n",
    "        power = 1 - nct.cdf(t_crit, df, ncp) + nct.cdf(-t_crit, df, ncp)\n",
    "        \n",
    "        # Minimum samples needed for 80% power\n",
    "        from scipy.optimize import fsolve\n",
    "        def power_eq(n):\n",
    "            ncp_n = cohen_d * np.sqrt(n)\n",
    "            t_crit_n = scipy_stats.t.ppf(1 - alpha/2, n - 1)\n",
    "            power_n = 1 - nct.cdf(t_crit_n, n - 1, ncp_n) + nct.cdf(-t_crit_n, n - 1, ncp_n)\n",
    "            return power_n - 0.80\n",
    "        \n",
    "        try:\n",
    "            min_samples = int(np.ceil(fsolve(power_eq, 10)[0]))\n",
    "        except:\n",
    "            min_samples = \">100\"\n",
    "        \n",
    "        detectable = \"✅ Yes\" if power >= 0.80 else \"⚠️  Marginal\" if power >= 0.50 else \"❌ No\"\n",
    "        \n",
    "        print(f\"  {effect_pct:>3}% improvement {detectable:<15} {power:.2%}    {min_samples}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **If baseline CV ≤ 10%**: 31 seeds can reliably detect improvements ≥5%\n",
    "   - Your 53% evaluation savings would be easily detected\n",
    "   - Even modest 3-5% improvements would show with good power\n",
    "\n",
    "2. **If baseline CV = 15%**: 31 seeds can detect improvements ≥10%\n",
    "   - Your 53% savings would still be very clear\n",
    "   - Smaller 3-5% effects might need more seeds\n",
    "\n",
    "3. **If baseline CV ≥ 20%**: May need more seeds for small effects\n",
    "   - But 53% improvement would still be detectable\n",
    "   - Consider increasing to 50+ seeds if variance is very high\n",
    "\n",
    "4. **Recommendation**: \n",
    "   - Run 3-5 baseline seeds first to estimate actual CV\n",
    "   - If CV < 15%, proceed with 31 seeds\n",
    "   - If CV > 15%, consider expanding to 50 seeds for better power\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1973862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

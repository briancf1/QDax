{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc23e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"git+https://github.com/briancf1/QDax.git#egg=qdax[examples]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository to get experiment scripts\n",
    "!git clone https://github.com/briancf1/QDax.git\n",
    "%cd QDax/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ca06a",
   "metadata": {},
   "source": [
    "## Humanoid Omni Environment - Full 31-Seed Study\n",
    "\n",
    "**Environment**: humanoid_omni (biped, 17 DoF, final xy position descriptor)\n",
    "**Purpose**: Test Competition-GA generalization to complex bipedal locomotion\n",
    "**Timeline**: Start at 3:15am, finish ~12:15pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import functools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from qdax.core.dns_ga import DominatedNoveltySearchGA\n",
    "from qdax.core.dns import DominatedNoveltySearch\n",
    "import qdax.tasks.brax as environments\n",
    "from qdax.tasks.brax.env_creators import scoring_function_brax_envs as scoring_function\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Create experiment logs directory\n",
    "os.makedirs(\"seed_variability_logs_humanoid_omni\", exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6db60a",
   "metadata": {},
   "source": [
    "## Generate Random Seeds (SAME as ant_omni for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SAME 31 seeds as ant_omni for direct comparison\n",
    "np.random.seed(2024)\n",
    "RANDOM_SEEDS = np.random.randint(1, 100000, size=31).tolist()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"USING SAME 31 RANDOM SEEDS AS ANT_OMNI\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Seeds: {RANDOM_SEEDS[:10]}... (showing first 10)\")\n",
    "print(f\"Total: {len(RANDOM_SEEDS)} seeds\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save seeds\n",
    "with open('seed_variability_logs_humanoid_omni/random_seeds.json', 'w') as f:\n",
    "    json.dump({'seeds': RANDOM_SEEDS, 'generation_seed': 2024}, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183fbae",
   "metadata": {},
   "source": [
    "## Experiment Configuration - Humanoid Omni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16cf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_PARAMS = {\n",
    "    'batch_size': 100,\n",
    "    'env_name': 'humanoid_omni',  # Bipedal humanoid, 17 DoF, xy position descriptor\n",
    "    'episode_length': 100,\n",
    "    'num_iterations': 3000,\n",
    "    'policy_hidden_layer_sizes': (64, 64),\n",
    "    'population_size': 1024,\n",
    "    'k': 3,\n",
    "    'line_sigma': 0.05,\n",
    "    'iso_sigma': 0.01,\n",
    "}\n",
    "\n",
    "MAIN_CONFIGS = [\n",
    "    # Baseline\n",
    "    {\n",
    "        'type': 'baseline',\n",
    "        'name': 'DNS_baseline',\n",
    "        'g_n': None,\n",
    "        'num_ga_children': None,\n",
    "        'num_ga_generations': None,\n",
    "    },\n",
    "    # Frequent GA\n",
    "    {\n",
    "        'type': 'dns-ga',\n",
    "        'name': 'DNS-GA_g300_gen2',\n",
    "        'g_n': 300,\n",
    "        'num_ga_children': 2,\n",
    "        'num_ga_generations': 2,\n",
    "    },\n",
    "    # Rare but deep GA\n",
    "    {\n",
    "        'type': 'dns-ga',\n",
    "        'name': 'DNS-GA_g1000_gen4',\n",
    "        'g_n': 1000,\n",
    "        'num_ga_children': 2,\n",
    "        'num_ga_generations': 4,\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HUMANOID OMNI CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nEnvironment: {FIXED_PARAMS['env_name']}\")\n",
    "print(f\"  Type: Bipedal humanoid\")\n",
    "print(f\"  DoF: 17 (most complex)\")\n",
    "print(f\"  Descriptor: Final xy position (2D)\")\n",
    "print(f\"  Iterations: {FIXED_PARAMS['num_iterations']}\")\n",
    "print(f\"  Seeds: {len(RANDOM_SEEDS)}\")\n",
    "\n",
    "print(f\"\\nConfigurations:\")\n",
    "for config in MAIN_CONFIGS:\n",
    "    if config['type'] == 'baseline':\n",
    "        print(f\"  â€¢ {config['name']}: No GA\")\n",
    "    else:\n",
    "        ga_calls = FIXED_PARAMS['num_iterations'] // config['g_n']\n",
    "        print(f\"  â€¢ {config['name']}: {ga_calls} GA calls\")\n",
    "\n",
    "total_exp = len(MAIN_CONFIGS) * len(RANDOM_SEEDS)\n",
    "print(f\"\\nTotal Experiments: {total_exp}\")\n",
    "print(f\"Estimated time (2-parallel): ~{(total_exp / 2) * 13.5 / 60:.1f} hours\")\n",
    "print(f\"Expected completion: ~12:15pm\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9b88e5",
   "metadata": {},
   "source": [
    "## Helper Functions (same as ant_omni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ga_overhead_evals(g_n, num_iterations, population_size, num_ga_children, num_ga_generations):\n",
    "    \"\"\"Calculate total evaluations performed by Competition-GA.\"\"\"\n",
    "    if g_n is None or g_n >= num_iterations:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    num_ga_calls = num_iterations // g_n\n",
    "    if num_ga_children == 1:\n",
    "        offspring_per_call = population_size * num_ga_generations\n",
    "    else:\n",
    "        offspring_per_call = population_size * num_ga_children * (num_ga_children**num_ga_generations - 1) // (num_ga_children - 1)\n",
    "    evals_per_ga_call = offspring_per_call\n",
    "    total_ga_evals = num_ga_calls * evals_per_ga_call\n",
    "    return total_ga_evals, num_ga_calls, evals_per_ga_call\n",
    "\n",
    "\n",
    "def setup_environment(env_name, episode_length, policy_hidden_layer_sizes, batch_size, seed):\n",
    "    \"\"\"Initialize environment and policy network.\"\"\"\n",
    "    env = environments.create(env_name, episode_length=episode_length)\n",
    "    reset_fn = jax.jit(env.reset)\n",
    "    key = jax.random.key(seed)\n",
    "    \n",
    "    policy_layer_sizes = policy_hidden_layer_sizes + (env.action_size,)\n",
    "    policy_network = MLP(\n",
    "        layer_sizes=policy_layer_sizes,\n",
    "        kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "        final_activation=jnp.tanh,\n",
    "    )\n",
    "    \n",
    "    key, subkey = jax.random.split(key)\n",
    "    keys = jax.random.split(subkey, num=batch_size)\n",
    "    fake_batch = jnp.zeros(shape=(batch_size, env.observation_size))\n",
    "    init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "    \n",
    "    return env, policy_network, reset_fn, init_variables, key\n",
    "\n",
    "\n",
    "def create_scoring_function(env, policy_network, reset_fn, episode_length, env_name):\n",
    "    \"\"\"Create scoring function for fitness evaluation.\"\"\"\n",
    "    def play_step_fn(env_state, policy_params, key):\n",
    "        actions = policy_network.apply(policy_params, env_state.obs)\n",
    "        state_desc = env_state.info[\"state_descriptor\"]\n",
    "        next_state = env.step(env_state, actions)\n",
    "        \n",
    "        transition = QDTransition(\n",
    "            obs=env_state.obs,\n",
    "            next_obs=next_state.obs,\n",
    "            rewards=next_state.reward,\n",
    "            dones=next_state.done,\n",
    "            actions=actions,\n",
    "            truncations=next_state.info[\"truncation\"],\n",
    "            state_desc=state_desc,\n",
    "            next_state_desc=next_state.info[\"state_descriptor\"],\n",
    "        )\n",
    "        return next_state, policy_params, key, transition\n",
    "    \n",
    "    descriptor_extraction_fn = environments.descriptor_extractor[env_name]\n",
    "    scoring_fn = functools.partial(\n",
    "        scoring_function,\n",
    "        episode_length=episode_length,\n",
    "        play_reset_fn=reset_fn,\n",
    "        play_step_fn=play_step_fn,\n",
    "        descriptor_extractor=descriptor_extraction_fn,\n",
    "    )\n",
    "    \n",
    "    return scoring_fn\n",
    "\n",
    "\n",
    "def create_mutation_function(iso_sigma):\n",
    "    \"\"\"Create mutation function for Competition-GA.\"\"\"\n",
    "    def competition_ga_mutation_fn(genotype, key):\n",
    "        genotype_flat, tree_def = jax.tree_util.tree_flatten(genotype)\n",
    "        num_leaves = len(genotype_flat)\n",
    "        keys = jax.random.split(key, num_leaves)\n",
    "        keys_tree = jax.tree_util.tree_unflatten(tree_def, keys)\n",
    "        \n",
    "        def add_noise(x, k):\n",
    "            return x + jax.random.normal(k, shape=x.shape) * iso_sigma\n",
    "        \n",
    "        mutated = jax.tree_util.tree_map(add_noise, genotype, keys_tree)\n",
    "        return mutated\n",
    "    \n",
    "    return competition_ga_mutation_fn\n",
    "\n",
    "print(\"Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e952b3",
   "metadata": {},
   "source": [
    "## Single Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(config, seed, fixed_params):\n",
    "    \"\"\"Run a single experiment with given config and seed.\"\"\"\n",
    "    exp_name = f\"{config['name']}_seed{seed}\"\n",
    "    \n",
    "    env, policy_network, reset_fn, init_variables, key = setup_environment(\n",
    "        fixed_params['env_name'],\n",
    "        fixed_params['episode_length'],\n",
    "        fixed_params['policy_hidden_layer_sizes'],\n",
    "        fixed_params['batch_size'],\n",
    "        seed\n",
    "    )\n",
    "    \n",
    "    scoring_fn = create_scoring_function(env, policy_network, reset_fn, \n",
    "                                        fixed_params['episode_length'],\n",
    "                                        fixed_params['env_name'])\n",
    "    \n",
    "    reward_offset = environments.reward_offset[fixed_params['env_name']]\n",
    "    metrics_function = functools.partial(\n",
    "        default_qd_metrics,\n",
    "        qd_offset=reward_offset * fixed_params['episode_length'],\n",
    "    )\n",
    "    \n",
    "    variation_fn = functools.partial(\n",
    "        isoline_variation,\n",
    "        iso_sigma=fixed_params['iso_sigma'],\n",
    "        line_sigma=fixed_params['line_sigma']\n",
    "    )\n",
    "    \n",
    "    mixing_emitter = MixingEmitter(\n",
    "        mutation_fn=None,\n",
    "        variation_fn=variation_fn,\n",
    "        variation_percentage=1.0,\n",
    "        batch_size=fixed_params['batch_size']\n",
    "    )\n",
    "    \n",
    "    if config['type'] == 'baseline':\n",
    "        algorithm = DominatedNoveltySearch(\n",
    "            scoring_function=scoring_fn,\n",
    "            emitter=mixing_emitter,\n",
    "            metrics_function=metrics_function,\n",
    "            population_size=fixed_params['population_size'],\n",
    "            k=fixed_params['k'],\n",
    "        )\n",
    "    else:\n",
    "        mutation_fn = create_mutation_function(fixed_params['iso_sigma'])\n",
    "        algorithm = DominatedNoveltySearchGA(\n",
    "            scoring_function=scoring_fn,\n",
    "            emitter=mixing_emitter,\n",
    "            metrics_function=metrics_function,\n",
    "            population_size=fixed_params['population_size'],\n",
    "            k=fixed_params['k'],\n",
    "            g_n=config['g_n'],\n",
    "            num_ga_children=config['num_ga_children'],\n",
    "            num_ga_generations=config['num_ga_generations'],\n",
    "            mutation_fn=mutation_fn,\n",
    "        )\n",
    "    \n",
    "    key, subkey = jax.random.split(key)\n",
    "    repertoire, emitter_state, init_metrics = algorithm.init(init_variables, subkey)\n",
    "    \n",
    "    log_period = 100\n",
    "    num_loops = fixed_params['num_iterations'] // log_period\n",
    "    \n",
    "    metrics = {key: jnp.array([]) for key in [\"iteration\", \"qd_score\", \"coverage\", \"max_fitness\", \"time\"]}\n",
    "    init_metrics = jax.tree.map(lambda x: jnp.array([x]) if x.shape == () else x, init_metrics)\n",
    "    init_metrics[\"iteration\"] = jnp.array([0], dtype=jnp.int32)\n",
    "    init_metrics[\"time\"] = jnp.array([0.0])\n",
    "    metrics = jax.tree.map(\n",
    "        lambda metric, init_metric: jnp.concatenate([metric, init_metric], axis=0),\n",
    "        metrics, init_metrics\n",
    "    )\n",
    "    \n",
    "    log_filename = os.path.join(\"seed_variability_logs_humanoid_omni\", f\"{exp_name}_logs.csv\")\n",
    "    csv_logger = CSVLogger(log_filename, header=list(metrics.keys()))\n",
    "    csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "    \n",
    "    if config['type'] == 'baseline':\n",
    "        scan_state = (repertoire, emitter_state, key)\n",
    "    else:\n",
    "        scan_state = (repertoire, emitter_state, key, 1)\n",
    "    \n",
    "    start_time_total = time.time()\n",
    "    \n",
    "    for i in range(num_loops):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        scan_state, current_metrics = jax.lax.scan(\n",
    "            algorithm.scan_update,\n",
    "            scan_state,\n",
    "            (),\n",
    "            length=log_period,\n",
    "        )\n",
    "        \n",
    "        timelapse = time.time() - start_time\n",
    "        \n",
    "        current_metrics[\"iteration\"] = jnp.arange(\n",
    "            1 + log_period * i, 1 + log_period * (i + 1), dtype=jnp.int32\n",
    "        )\n",
    "        current_metrics[\"time\"] = jnp.repeat(timelapse, log_period)\n",
    "        metrics = jax.tree.map(\n",
    "            lambda metric, current_metric: jnp.concatenate([metric, current_metric], axis=0),\n",
    "            metrics, current_metrics\n",
    "        )\n",
    "        \n",
    "        csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "    \n",
    "    total_time = time.time() - start_time_total\n",
    "    \n",
    "    ga_total_evals, ga_num_calls, ga_evals_per_call = calculate_ga_overhead_evals(\n",
    "        config.get('g_n'), fixed_params['num_iterations'], fixed_params['population_size'],\n",
    "        config.get('num_ga_children'), config.get('num_ga_generations')\n",
    "    )\n",
    "    \n",
    "    # Save final repertoire for behavior space visualization\n",
    "    # Extract final repertoire state from scan_state\n",
    "    if config['type'] == 'baseline':\n",
    "        final_repertoire = scan_state[0]  # (repertoire, emitter_state, key)\n",
    "    else:\n",
    "        final_repertoire = scan_state[0]  # (repertoire, emitter_state, key, generation_counter)\n",
    "    \n",
    "    repertoire_file = os.path.join(\"seed_variability_logs_humanoid_omni\", f\"{exp_name}_repertoire.npz\")\n",
    "    jnp.savez(repertoire_file,\n",
    "        descriptors=final_repertoire.descriptors,\n",
    "        fitnesses=final_repertoire.fitnesses\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'config_name': config['name'],\n",
    "        'config_type': config['type'],\n",
    "        'seed': seed,\n",
    "        'g_n': config.get('g_n'),\n",
    "        'num_ga_generations': config.get('num_ga_generations'),\n",
    "        'final_qd_score': float(metrics['qd_score'][-1]),\n",
    "        'final_max_fitness': float(metrics['max_fitness'][-1]),\n",
    "        'final_coverage': float(metrics['coverage'][-1]),\n",
    "        'total_time': total_time,\n",
    "        'ga_overhead_evals': ga_total_evals,\n",
    "        'log_file': log_filename,\n",
    "        'repertoire_file': repertoire_file,\n",
    "    }\n",
    "\n",
    "print(\"Experiment runner ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38c786",
   "metadata": {},
   "source": [
    "## Build Queue and Run Experiments (2-Parallel with ipyparallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"BUILDING EXPERIMENT QUEUE - {timestamp}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "experiment_queue = []\n",
    "exp_num = 0\n",
    "\n",
    "for config in MAIN_CONFIGS:\n",
    "    for seed in RANDOM_SEEDS:\n",
    "        exp_num += 1\n",
    "        experiment_queue.append((exp_num, exp_num, config, seed))\n",
    "\n",
    "print(f\"\\nTotal experiments: {len(experiment_queue)}\")\n",
    "print(f\"Execution: 2-parallel with ipyparallel\")\n",
    "print(f\"Estimated time: ~{len(experiment_queue) / 2 * 13.5 / 60:.1f} hours\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING HUMANOID_OMNI EXPERIMENTS (2-PARALLEL)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Expected completion: ~12:15pm\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time_all = time.time()\n",
    "\n",
    "import ipyparallel as ipp\n",
    "\n",
    "cluster = ipp.Cluster(n=2)\n",
    "rc = cluster.start_and_connect_sync()\n",
    "\n",
    "print(f\"âœ“ Cluster started with {len(rc)} engines\")\n",
    "\n",
    "rc[:].execute(\"\"\"\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "import time\n",
    "import os\n",
    "from qdax.core.dns_ga import DominatedNoveltySearchGA\n",
    "from qdax.core.dns import DominatedNoveltySearch\n",
    "import qdax.tasks.brax as environments\n",
    "from qdax.tasks.brax.env_creators import scoring_function_brax_envs as scoring_function\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "\"\"\").wait()\n",
    "\n",
    "rc[:].push({\n",
    "    'FIXED_PARAMS': FIXED_PARAMS,\n",
    "    'setup_environment': setup_environment,\n",
    "    'create_scoring_function': create_scoring_function,\n",
    "    'create_mutation_function': create_mutation_function,\n",
    "    'calculate_ga_overhead_evals': calculate_ga_overhead_evals,\n",
    "    'run_single_experiment': run_single_experiment\n",
    "}).wait()\n",
    "\n",
    "print(\"âœ“ Engines initialized\")\n",
    "\n",
    "def run_experiment_wrapper(exp_tuple):\n",
    "    exp_num, total_exp, config, seed = exp_tuple\n",
    "    try:\n",
    "        result = run_single_experiment(config, seed, FIXED_PARAMS)\n",
    "        result['exp_num'] = exp_num\n",
    "        return ('success', result)\n",
    "    except Exception as e:\n",
    "        return ('error', {'config_name': config['name'], 'seed': seed, 'error': str(e)})\n",
    "\n",
    "rc[:].push({'run_experiment_wrapper': run_experiment_wrapper}).wait()\n",
    "\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "print(\"Submitting all experiments...\")\n",
    "async_results = []\n",
    "for exp_tuple in experiment_queue:\n",
    "    ar = lview.apply_async(run_experiment_wrapper, exp_tuple)\n",
    "    async_results.append(ar)\n",
    "\n",
    "print(f\"âœ“ Submitted {len(async_results)} experiments\")\n",
    "print(\"\\nMonitoring progress...\")\n",
    "\n",
    "all_results = []\n",
    "errors = []\n",
    "completed_count = 0\n",
    "last_update = time.time()\n",
    "\n",
    "while completed_count < len(async_results):\n",
    "    for ar in async_results:\n",
    "        if ar.ready() and not hasattr(ar, '_collected'):\n",
    "            ar._collected = True\n",
    "            status, result = ar.result()\n",
    "            \n",
    "            if status == 'success':\n",
    "                all_results.append(result)\n",
    "                print(f\"  âœ“ Completed: {result['config_name']}, seed={result['seed']}, QD={result['final_qd_score']:.1f}\")\n",
    "            else:\n",
    "                errors.append(result)\n",
    "                print(f\"  âœ— Failed: {result['config_name']}, seed={result['seed']}\")\n",
    "            \n",
    "            completed_count += 1\n",
    "    \n",
    "    if time.time() - last_update > 10:\n",
    "        elapsed = time.time() - start_time_all\n",
    "        pct = completed_count / len(experiment_queue) * 100\n",
    "        if completed_count > 0:\n",
    "            avg_time = elapsed / completed_count\n",
    "            remaining_time = (len(experiment_queue) - completed_count) * avg_time / 3600\n",
    "            print(f\"ðŸ“Š Progress: {completed_count}/{len(experiment_queue)} ({pct:.1f}%) | Elapsed: {elapsed/60:.1f}m | Remaining: ~{remaining_time:.2f}h\")\n",
    "        last_update = time.time()\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "cluster.stop_cluster_sync()\n",
    "print(\"\\nâœ“ Cluster stopped\")\n",
    "\n",
    "total_time = time.time() - start_time_all\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HUMANOID_OMNI EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total time: {total_time / 60:.1f} minutes ({total_time / 3600:.2f} hours)\")\n",
    "print(f\"Successful: {len(all_results)}/{len(experiment_queue)}\")\n",
    "print(f\"Failed: {len(errors)}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for error in errors:\n",
    "        print(f\"  â€¢ {error['config_name']}, seed={error['seed']}\")\n",
    "\n",
    "results_file = f\"seed_variability_logs_humanoid_omni/all_results_{timestamp}.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'results': all_results,\n",
    "        'errors': errors,\n",
    "        'total_time': total_time,\n",
    "        'timestamp': timestamp,\n",
    "        'environment': 'humanoid_omni',\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: {results_file}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ced0d",
   "metadata": {},
   "source": [
    "## Quick Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84693a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_results) > 0:\n",
    "    df = pd.DataFrame(all_results)\n",
    "    print(\"=\"*80)\n",
    "    print(\"HUMANOID_OMNI RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal experiments: {len(df)}\")\n",
    "    print(\"\\nFinal QD Scores by Configuration:\")\n",
    "    print(df.groupby('config_name')['final_qd_score'].agg(['mean', 'std', 'min', 'max']).round(2))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ“ Results ready for integration with ant_omni and walker2d data\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b260cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 1. Mount your Google Drive ---\n",
    "# This will pop up an authorization window the first time.\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- 2. Create a unique filename with a timestamp ---\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "zip_filename = f\"QDax_backup_{timestamp}.zip\"\n",
    "drive_save_path = f\"/content/drive/MyDrive/Colab_Backups/{zip_filename}\"\n",
    "\n",
    "# Create the backup directory in your Drive if it doesn't exist\n",
    "os.makedirs(\"/content/drive/MyDrive/Colab_Backups\", exist_ok=True)\n",
    "\n",
    "# --- 3. Zip the directory and save it to Google Drive ---\n",
    "# -q = quiet (no file list)\n",
    "# -r = recursive (include all subdirectories)\n",
    "print(f\"Zipping /content/QDax/ ...\")\n",
    "!zip -q -r {drive_save_path} /content/QDax/\n",
    "\n",
    "print(f\"âœ… Successfully saved backup to: {drive_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

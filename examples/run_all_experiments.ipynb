{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"git+https://github.com/briancf1/QDax.git#egg=qdax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cf796",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06529531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Current directory: /Users/briancf/Desktop/source/EvoAlgsAndSwarm/lib-qdax/QDax/examples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Create experiment logs directory\n",
    "os.makedirs(\"experiment_logs\", exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd2f46",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600ec271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def run_script(script_name, log_suffix):\n",
    "    \"\"\"\n",
    "    Run a Python script and capture output to log file.\n",
    "    \n",
    "    Args:\n",
    "        script_name: Name of the Python script to run\n",
    "        log_suffix: Suffix for the log file\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (success, runtime_seconds, log_file)\n",
    "    \"\"\"\n",
    "    log_file = f\"experiment_logs/{log_suffix}.log\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Running: {script_name}\")\n",
    "    print(f\"Log file: {log_file}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        with open(log_file, 'w') as f:\n",
    "            process = subprocess.Popen(\n",
    "                ['python', '-u', script_name],\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                bufsize=1\n",
    "            )\n",
    "            \n",
    "            # Stream output to both log file and notebook\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')\n",
    "                f.write(line)\n",
    "            \n",
    "            process.wait()\n",
    "            runtime = time.time() - start_time\n",
    "            \n",
    "            if process.returncode == 0:\n",
    "                print(f\"\\n✓ SUCCESS - Runtime: {runtime:.1f}s\")\n",
    "                return True, runtime, log_file\n",
    "            else:\n",
    "                print(f\"\\n✗ FAILED - Exit code: {process.returncode}\")\n",
    "                return False, runtime, log_file\n",
    "                \n",
    "    except Exception as e:\n",
    "        runtime = time.time() - start_time\n",
    "        print(f\"\\n✗ ERROR: {e}\")\n",
    "        return False, runtime, log_file\n",
    "\n",
    "\n",
    "def summarize_results(results_json_path):\n",
    "    \"\"\"\n",
    "    Load and display summary from results JSON.\n",
    "    \n",
    "    Args:\n",
    "        results_json_path: Path to the results JSON file\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(results_json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        results = data.get('results', [])\n",
    "        if not results:\n",
    "            print(f\"No results found in {results_json_path}\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Results file not found: {results_json_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e6cd5",
   "metadata": {},
   "source": [
    "## 1. Run Baseline DNS Experiments\n",
    "\n",
    "Tests different mutation strengths (iso_sigma) to determine if mutation tuning alone improves DNS performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d058b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running: run_baselines.py\n",
      "Log file: experiment_logs/baselines.log\n",
      "================================================================================\n",
      "Failed to import warp: No module named 'warp'\n",
      "Failed to import mujoco_warp: No module named 'warp'\n",
      "Failed to import warp: No module named 'warp'\n",
      "Failed to import mujoco_warp: No module named 'warp'\n",
      "reached\n",
      "\n",
      "================================================================================\n",
      "DNS Baseline Experiments - 20251115_113522\n",
      "================================================================================\n",
      "Output directory: dns_baselines_20251115_113522\n",
      "Total experiments: 3\n",
      "Purpose: Test if iso_sigma affects DNS performance\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 1/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS_baseline_iso0.005\n",
      "================================================================================\n",
      "/Users/briancf/Desktop/source/EvoAlgsAndSwarm/lib-qdax/QDax/.venv/lib/python3.12/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n",
      "reached\n",
      "\n",
      "================================================================================\n",
      "DNS Baseline Experiments - 20251115_113522\n",
      "================================================================================\n",
      "Output directory: dns_baselines_20251115_113522\n",
      "Total experiments: 3\n",
      "Purpose: Test if iso_sigma affects DNS performance\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 1/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS_baseline_iso0.005\n",
      "================================================================================\n",
      "/Users/briancf/Desktop/source/EvoAlgsAndSwarm/lib-qdax/QDax/.venv/lib/python3.12/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n",
      "Config: Standard DNS, iso_sigma=0.005\n",
      "Config: Standard DNS, iso_sigma=0.005\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "\n",
      "Completed in 53.63s\n",
      "Final - QD: 348118.69, MaxFit: 245.51, Cov: 100.00%\n",
      "\n",
      ">>> Baseline target QD set to: 348118.69 <<<\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 2/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS_baseline_iso0.01\n",
      "================================================================================\n",
      "Config: Standard DNS, iso_sigma=0.01\n",
      "\n",
      "Completed in 53.63s\n",
      "Final - QD: 348118.69, MaxFit: 245.51, Cov: 100.00%\n",
      "\n",
      ">>> Baseline target QD set to: 348118.69 <<<\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 2/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS_baseline_iso0.01\n",
      "================================================================================\n",
      "Config: Standard DNS, iso_sigma=0.01\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "\n",
      ">>> Converged at iteration 200 <<<\n",
      "\n",
      "\n",
      ">>> Converged at iteration 200 <<<\n",
      "\n",
      "\n",
      "Completed in 54.68s\n",
      "Final - QD: 368943.94, MaxFit: 268.49, Cov: 100.00%\n",
      "Convergence: iter 200, savings: 60.0%\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 3/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS_baseline_iso0.003\n",
      "================================================================================\n",
      "Config: Standard DNS, iso_sigma=0.003\n",
      "\n",
      "Completed in 54.68s\n",
      "Final - QD: 368943.94, MaxFit: 268.49, Cov: 100.00%\n",
      "Convergence: iter 200, savings: 60.0%\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 3/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS_baseline_iso0.003\n",
      "================================================================================\n",
      "Config: Standard DNS, iso_sigma=0.003\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "\n",
      ">>> Converged at iteration 300 <<<\n",
      "\n",
      "\n",
      ">>> Converged at iteration 300 <<<\n",
      "\n",
      "\n",
      "Completed in 53.91s\n",
      "Final - QD: 364761.06, MaxFit: 253.57, Cov: 100.00%\n",
      "Convergence: iter 300, savings: 40.0%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BASELINE RESULTS\n",
      "================================================================================\n",
      "DNS_baseline_iso0.01           QD= 368943.94\n",
      "DNS_baseline_iso0.003          QD= 364761.06\n",
      "DNS_baseline_iso0.005          QD= 348118.69\n",
      "\n",
      "\n",
      "Results saved to: dns_baselines_20251115_113522\n",
      "\n",
      "Completed in 53.91s\n",
      "Final - QD: 364761.06, MaxFit: 253.57, Cov: 100.00%\n",
      "Convergence: iter 300, savings: 40.0%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BASELINE RESULTS\n",
      "================================================================================\n",
      "DNS_baseline_iso0.01           QD= 368943.94\n",
      "DNS_baseline_iso0.003          QD= 364761.06\n",
      "DNS_baseline_iso0.005          QD= 348118.69\n",
      "\n",
      "\n",
      "Results saved to: dns_baselines_20251115_113522\n",
      "\n",
      "✓ SUCCESS - Runtime: 175.9s\n",
      "\n",
      "Baseline experiments completed\n",
      "Total runtime: 175.9s (2.9 minutes)\n",
      "\n",
      "✓ SUCCESS - Runtime: 175.9s\n",
      "\n",
      "Baseline experiments completed\n",
      "Total runtime: 175.9s (2.9 minutes)\n"
     ]
    }
   ],
   "source": [
    "baseline_success, baseline_time, baseline_log = run_script(\n",
    "    'run_baselines.py',\n",
    "    'baselines'\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline experiments {'completed' if baseline_success else 'failed'}\")\n",
    "print(f\"Total runtime: {baseline_time:.1f}s ({baseline_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79244c",
   "metadata": {},
   "source": [
    "### Baseline Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7754ceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline DNS Results:\n",
      "                 name  final_qd_score  final_max_fitness  final_coverage  total_time\n",
      "DNS_baseline_iso0.005     348118.6875         245.510559           100.0   53.629239\n",
      " DNS_baseline_iso0.01     368943.9375         268.489227           100.0   54.675574\n",
      "DNS_baseline_iso0.003     364761.0625         253.565811           100.0   53.907988\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent baseline results directory\n",
    "baseline_dirs = sorted([d for d in os.listdir('.') if d.startswith('dns_baselines_')])\n",
    "if baseline_dirs:\n",
    "    latest_baseline = baseline_dirs[-1]\n",
    "    baseline_results_path = os.path.join(latest_baseline, 'baseline_results.json')\n",
    "    \n",
    "    baseline_df = summarize_results(baseline_results_path)\n",
    "    if baseline_df is not None:\n",
    "        print(\"\\nBaseline DNS Results:\")\n",
    "        print(baseline_df[['name', 'final_qd_score', 'final_max_fitness', 'final_coverage', 'total_time']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No baseline results found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa958ce",
   "metadata": {},
   "source": [
    "## 2. Run Tier 1: Proven Winners\n",
    "\n",
    "Top 3 configurations from initial results (g300_gen2, g614_gen2, g250_gen1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3cfad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running: run_tier1_proven_winners.py\n",
      "Log file: experiment_logs/tier1_proven_winners.log\n",
      "================================================================================\n",
      "Failed to import warp: No module named 'warp'\n",
      "Failed to import mujoco_warp: No module named 'warp'\n",
      "Failed to import warp: No module named 'warp'\n",
      "Failed to import mujoco_warp: No module named 'warp'\n",
      "Loaded baseline target from dns_baselines_20251115_113522/baseline_results.json: 348118.69\n",
      "reached\n",
      "\n",
      "================================================================================\n",
      "DNS-GA Tier 1: Proven Winners - 20251115_114536\n",
      "================================================================================\n",
      "Output directory: dns_ga_tier1_20251115_114536\n",
      "Total experiments: 3\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 1/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS-GA_g300_gen2_iso0.005\n",
      "================================================================================\n",
      "/Users/briancf/Desktop/source/EvoAlgsAndSwarm/lib-qdax/QDax/.venv/lib/python3.12/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n",
      "Loaded baseline target from dns_baselines_20251115_113522/baseline_results.json: 348118.69\n",
      "reached\n",
      "\n",
      "================================================================================\n",
      "DNS-GA Tier 1: Proven Winners - 20251115_114536\n",
      "================================================================================\n",
      "Output directory: dns_ga_tier1_20251115_114536\n",
      "Total experiments: 3\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 1/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS-GA_g300_gen2_iso0.005\n",
      "================================================================================\n",
      "/Users/briancf/Desktop/source/EvoAlgsAndSwarm/lib-qdax/QDax/.venv/lib/python3.12/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n",
      "Config: g_n=300, gens=2, iso_sigma=0.005\n",
      "Config: g_n=300, gens=2, iso_sigma=0.005\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "\n",
      ">>> Converged at iteration 300 (reached baseline QD target) <<<\n",
      "\n",
      "\n",
      ">>> Converged at iteration 300 (reached baseline QD target) <<<\n",
      "\n",
      "\n",
      "Completed in 62.18s\n",
      "Final - QD: 358458.78, MaxFit: 258.21, Cov: 100.00%\n",
      "\n",
      "Evaluation Analysis:\n",
      "  Convergence iteration: 300\n",
      "  Baseline total evals: 50,000\n",
      "  DNS-GA main evals: 30,000\n",
      "  DNS-GA overhead evals: 6,144 (1 GA calls)\n",
      "  DNS-GA total evals: 36,144\n",
      "  Convergence speedup: 40.0%\n",
      "  Net evaluation savings: 27.7%\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 2/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS-GA_g614_gen2_iso0.005\n",
      "================================================================================\n",
      "Config: g_n=614, gens=2, iso_sigma=0.005\n",
      "\n",
      "Completed in 62.18s\n",
      "Final - QD: 358458.78, MaxFit: 258.21, Cov: 100.00%\n",
      "\n",
      "Evaluation Analysis:\n",
      "  Convergence iteration: 300\n",
      "  Baseline total evals: 50,000\n",
      "  DNS-GA main evals: 30,000\n",
      "  DNS-GA overhead evals: 6,144 (1 GA calls)\n",
      "  DNS-GA total evals: 36,144\n",
      "  Convergence speedup: 40.0%\n",
      "  Net evaluation savings: 27.7%\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 2/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS-GA_g614_gen2_iso0.005\n",
      "================================================================================\n",
      "Config: g_n=614, gens=2, iso_sigma=0.005\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "\n",
      ">>> Converged at iteration 300 (reached baseline QD target) <<<\n",
      "\n",
      "\n",
      ">>> Converged at iteration 300 (reached baseline QD target) <<<\n",
      "\n",
      "\n",
      "Completed in 58.90s\n",
      "Final - QD: 358600.28, MaxFit: 259.98, Cov: 100.00%\n",
      "\n",
      "Evaluation Analysis:\n",
      "  Convergence iteration: 300\n",
      "  Baseline total evals: 50,000\n",
      "  DNS-GA main evals: 30,000\n",
      "  DNS-GA overhead evals: 0 (0 GA calls)\n",
      "  DNS-GA total evals: 30,000\n",
      "  Convergence speedup: 40.0%\n",
      "  Net evaluation savings: 40.0%\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 3/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS-GA_g250_gen1_iso0.005\n",
      "================================================================================\n",
      "Config: g_n=250, gens=1, iso_sigma=0.005\n",
      "\n",
      "Completed in 58.90s\n",
      "Final - QD: 358600.28, MaxFit: 259.98, Cov: 100.00%\n",
      "\n",
      "Evaluation Analysis:\n",
      "  Convergence iteration: 300\n",
      "  Baseline total evals: 50,000\n",
      "  DNS-GA main evals: 30,000\n",
      "  DNS-GA overhead evals: 0 (0 GA calls)\n",
      "  DNS-GA total evals: 30,000\n",
      "  Convergence speedup: 40.0%\n",
      "  Net evaluation savings: 40.0%\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# Experiment 3/3\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Running: DNS-GA_g250_gen1_iso0.005\n",
      "================================================================================\n",
      "Config: g_n=250, gens=1, iso_sigma=0.005\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "Initial - QD: 22903.10, MaxFit: 179.28, Coverage: 9.77\n",
      "\n",
      ">>> Converged at iteration 500 (reached baseline QD target) <<<\n",
      "\n",
      "\n",
      "Completed in 59.90s\n",
      "Final - QD: 350923.19, MaxFit: 245.66, Cov: 100.00%\n",
      "\n",
      "Evaluation Analysis:\n",
      "  Convergence iteration: 500\n",
      "  Baseline total evals: 50,000\n",
      "  DNS-GA main evals: 50,000\n",
      "  DNS-GA overhead evals: 4,096 (2 GA calls)\n",
      "  DNS-GA total evals: 54,096\n",
      "  Convergence speedup: 0.0%\n",
      "  Net evaluation savings: -8.2%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TIER 1 RESULTS\n",
      "================================================================================\n",
      "DNS-GA_g614_gen2_iso0.005           QD= 358600.28\n",
      "DNS-GA_g300_gen2_iso0.005           QD= 358458.78\n",
      "DNS-GA_g250_gen1_iso0.005           QD= 350923.19\n",
      "\n",
      "\n",
      "Results saved to: dns_ga_tier1_20251115_114536\n",
      "\n",
      ">>> Converged at iteration 500 (reached baseline QD target) <<<\n",
      "\n",
      "\n",
      "Completed in 59.90s\n",
      "Final - QD: 350923.19, MaxFit: 245.66, Cov: 100.00%\n",
      "\n",
      "Evaluation Analysis:\n",
      "  Convergence iteration: 500\n",
      "  Baseline total evals: 50,000\n",
      "  DNS-GA main evals: 50,000\n",
      "  DNS-GA overhead evals: 4,096 (2 GA calls)\n",
      "  DNS-GA total evals: 54,096\n",
      "  Convergence speedup: 0.0%\n",
      "  Net evaluation savings: -8.2%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TIER 1 RESULTS\n",
      "================================================================================\n",
      "DNS-GA_g614_gen2_iso0.005           QD= 358600.28\n",
      "DNS-GA_g300_gen2_iso0.005           QD= 358458.78\n",
      "DNS-GA_g250_gen1_iso0.005           QD= 350923.19\n",
      "\n",
      "\n",
      "Results saved to: dns_ga_tier1_20251115_114536\n",
      "\n",
      "✓ SUCCESS - Runtime: 213.2s\n",
      "\n",
      "Tier 1 experiments completed\n",
      "Total runtime: 213.2s (3.6 minutes)\n",
      "\n",
      "✓ SUCCESS - Runtime: 213.2s\n",
      "\n",
      "Tier 1 experiments completed\n",
      "Total runtime: 213.2s (3.6 minutes)\n"
     ]
    }
   ],
   "source": [
    "tier1_success, tier1_time, tier1_log = run_script(\n",
    "    'run_tier1_proven_winners.py',\n",
    "    'tier1_proven_winners'\n",
    ")\n",
    "\n",
    "print(f\"\\nTier 1 experiments {'completed' if tier1_success else 'failed'}\")\n",
    "print(f\"Total runtime: {tier1_time:.1f}s ({tier1_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d5680",
   "metadata": {},
   "source": [
    "### Tier 1 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4c370ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tier 1 Results:\n",
      "                     name  final_qd_score  convergence_iter  eval_savings_pct  net_eval_savings_pct\n",
      "DNS-GA_g300_gen2_iso0.005    358458.78125               300              40.0                27.712\n",
      "DNS-GA_g614_gen2_iso0.005    358600.28125               300              40.0                40.000\n",
      "DNS-GA_g250_gen1_iso0.005    350923.18750               500               0.0                -8.192\n"
     ]
    }
   ],
   "source": [
    "tier1_dirs = sorted([d for d in os.listdir('.') if d.startswith('dns_ga_tier1_')])\n",
    "if tier1_dirs:\n",
    "    latest_tier1 = tier1_dirs[-1]\n",
    "    tier1_results_path = os.path.join(latest_tier1, 'tier1_results.json')\n",
    "    \n",
    "    tier1_df = summarize_results(tier1_results_path)\n",
    "    if tier1_df is not None:\n",
    "        print(\"\\nTier 1 Results:\")\n",
    "        display_cols = ['name', 'final_qd_score', 'convergence_iter']\n",
    "        if 'net_eval_savings_pct' in tier1_df.columns:\n",
    "            display_cols.extend(['eval_savings_pct', 'net_eval_savings_pct'])\n",
    "        else:\n",
    "            display_cols.extend(['eval_savings_pct'])\n",
    "        print(tier1_df[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"No tier 1 results found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7ff21",
   "metadata": {},
   "source": [
    "## 3. Run Tier 2: Promising Configurations\n",
    "\n",
    "Low-overhead configurations (g500_gen1, g400_gen2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier2_success, tier2_time, tier2_log = run_script(\n",
    "    'run_tier2_promising.py',\n",
    "    'tier2_promising'\n",
    ")\n",
    "\n",
    "print(f\"\\nTier 2 experiments {'completed' if tier2_success else 'failed'}\")\n",
    "print(f\"Total runtime: {tier2_time:.1f}s ({tier2_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c7ca5",
   "metadata": {},
   "source": [
    "## 4. Run Tier 3: Deep Foresight\n",
    "\n",
    "Deeper forecasting with 3-4 generations (g500_gen3, g700_gen3, g1000_gen4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier3_success, tier3_time, tier3_log = run_script(\n",
    "    'run_tier3_deep_foresight.py',\n",
    "    'tier3_deep_foresight'\n",
    ")\n",
    "\n",
    "print(f\"\\nTier 3 experiments {'completed' if tier3_success else 'failed'}\")\n",
    "print(f\"Total runtime: {tier3_time:.1f}s ({tier3_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e8878",
   "metadata": {},
   "source": [
    "## 5. Run Tier 4: Aggressive Frequency\n",
    "\n",
    "Very frequent GA calls (g150_gen1, g200_gen2) to test overhead limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier4_success, tier4_time, tier4_log = run_script(\n",
    "    'run_tier4_aggressive.py',\n",
    "    'tier4_aggressive'\n",
    ")\n",
    "\n",
    "print(f\"\\nTier 4 experiments {'completed' if tier4_success else 'failed'}\")\n",
    "print(f\"Total runtime: {tier4_time:.1f}s ({tier4_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc957",
   "metadata": {},
   "source": [
    "## 6. Run Tier 5: Rare Deep Forecasting\n",
    "\n",
    "Rare but very deep forecasting (g1000_gen5, g1500_gen5) with 5 generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90363402",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier5_success, tier5_time, tier5_log = run_script(\n",
    "    'run_tier5_rare_deep.py',\n",
    "    'tier5_rare_deep'\n",
    ")\n",
    "\n",
    "print(f\"\\nTier 5 experiments {'completed' if tier5_success else 'failed'}\")\n",
    "print(f\"Total runtime: {tier5_time:.1f}s ({tier5_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee791f6c",
   "metadata": {},
   "source": [
    "## 7. Run Adaptive Experiments\n",
    "\n",
    "Tests dynamic g_n scheduling strategies where Competition-GA frequency changes during evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_success, adaptive_time, adaptive_log = run_script(\n",
    "    'run_adaptive_experiments.py',\n",
    "    'adaptive_experiments'\n",
    ")\n",
    "\n",
    "print(f\"\\nAdaptive experiments {'completed' if adaptive_success else 'failed'}\")\n",
    "print(f\"Total runtime: {adaptive_time:.1f}s ({adaptive_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc5402",
   "metadata": {},
   "source": [
    "### Adaptive Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_dirs = sorted([d for d in os.listdir('.') if d.startswith('dns_ga_adaptive_')])\n",
    "if adaptive_dirs:\n",
    "    latest_adaptive = adaptive_dirs[-1]\n",
    "    adaptive_results_path = os.path.join(latest_adaptive, 'adaptive_results.json')\n",
    "    \n",
    "    adaptive_df = summarize_results(adaptive_results_path)\n",
    "    if adaptive_df is not None:\n",
    "        print(\"\\nAdaptive Experiment Results:\")\n",
    "        print(adaptive_df[['name', 'final_qd_score', 'final_max_fitness', 'final_coverage']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No adaptive results found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6afa6c",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Analysis\n",
    "\n",
    "Now let's analyze and visualize all results together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75899765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = []\n",
    "\n",
    "# Baseline results\n",
    "if baseline_dirs:\n",
    "    baseline_df = summarize_results(os.path.join(baseline_dirs[-1], 'baseline_results.json'))\n",
    "    if baseline_df is not None:\n",
    "        baseline_df['category'] = 'Baseline'\n",
    "        all_results.append(baseline_df)\n",
    "\n",
    "# Tier results\n",
    "for tier_num in range(1, 6):\n",
    "    tier_dirs = sorted([d for d in os.listdir('.') if d.startswith(f'dns_ga_tier{tier_num}_')])\n",
    "    if tier_dirs:\n",
    "        tier_df = summarize_results(os.path.join(tier_dirs[-1], f'tier{tier_num}_results.json'))\n",
    "        if tier_df is not None:\n",
    "            tier_df['category'] = f'Tier {tier_num}'\n",
    "            all_results.append(tier_df)\n",
    "\n",
    "# Adaptive results\n",
    "if adaptive_dirs:\n",
    "    adaptive_df = summarize_results(os.path.join(adaptive_dirs[-1], 'adaptive_results.json'))\n",
    "    if adaptive_df is not None:\n",
    "        adaptive_df['category'] = 'Adaptive'\n",
    "        all_results.append(adaptive_df)\n",
    "\n",
    "if all_results:\n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    print(f\"\\nTotal experiments analyzed: {len(combined_df)}\")\n",
    "    print(\"\\nCategories:\")\n",
    "    print(combined_df['category'].value_counts())\n",
    "else:\n",
    "    print(\"No results to analyze yet\")\n",
    "    combined_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f93e1",
   "metadata": {},
   "source": [
    "### Visualization: Final QD Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combined_df is not None:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Sort by QD score\n",
    "    plot_df = combined_df.sort_values('final_qd_score', ascending=False)\n",
    "    \n",
    "    # Create bar plot\n",
    "    colors = {'Baseline': 'gray', 'Tier 1': 'green', 'Tier 2': 'blue', \n",
    "              'Tier 3': 'orange', 'Tier 4': 'red', 'Tier 5': 'purple', 'Adaptive': 'cyan'}\n",
    "    \n",
    "    bars = plt.bar(range(len(plot_df)), plot_df['final_qd_score'], \n",
    "                   color=[colors.get(cat, 'lightgray') for cat in plot_df['category']])\n",
    "    \n",
    "    plt.xlabel('Experiment', fontsize=12)\n",
    "    plt.ylabel('Final QD Score', fontsize=12)\n",
    "    plt.title('Final QD Scores - All Experiments', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(plot_df)), plot_df['name'], rotation=90, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=colors[cat], label=cat) for cat in colors.keys() if cat in plot_df['category'].values]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print top 5\n",
    "    print(\"\\nTop 5 Experiments by QD Score:\")\n",
    "    print(plot_df[['name', 'category', 'final_qd_score']].head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e174867",
   "metadata": {},
   "source": [
    "### Visualization: Evaluation Savings (DNS-GA only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combined_df is not None and 'eval_savings_pct' in combined_df.columns:\n",
    "    ga_df = combined_df[combined_df['eval_savings_pct'].notna()].copy()\n",
    "    \n",
    "    if len(ga_df) > 0:\n",
    "        # Create two subplots: convergence speedup vs net savings\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Plot 1: Convergence speedup (ignoring overhead)\n",
    "        ga_df_sorted = ga_df.sort_values('eval_savings_pct', ascending=False)\n",
    "        bars1 = ax1.bar(range(len(ga_df_sorted)), ga_df_sorted['eval_savings_pct'],\n",
    "                       color=[colors.get(cat, 'lightgray') for cat in ga_df_sorted['category']])\n",
    "        ax1.set_xlabel('DNS-GA Configuration', fontsize=12)\n",
    "        ax1.set_ylabel('Convergence Speedup (%)', fontsize=12)\n",
    "        ax1.set_title('Convergence Speedup (iterations saved, ignoring GA overhead)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_xticks(range(len(ga_df_sorted)))\n",
    "        ax1.set_xticklabels(ga_df_sorted['name'], rotation=90, ha='right')\n",
    "        ax1.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Net evaluation savings (accounting for overhead)\n",
    "        if 'net_eval_savings_pct' in ga_df.columns:\n",
    "            ga_df_net = ga_df[ga_df['net_eval_savings_pct'].notna()].sort_values('net_eval_savings_pct', ascending=False)\n",
    "            bars2 = ax2.bar(range(len(ga_df_net)), ga_df_net['net_eval_savings_pct'],\n",
    "                           color=[colors.get(cat, 'lightgray') for cat in ga_df_net['category']])\n",
    "            ax2.set_xlabel('DNS-GA Configuration', fontsize=12)\n",
    "            ax2.set_ylabel('Net Evaluation Savings (%)', fontsize=12)\n",
    "            ax2.set_title('Net Evaluation Savings (accounting for GA overhead)', fontsize=12, fontweight='bold')\n",
    "            ax2.set_xticks(range(len(ga_df_net)))\n",
    "            ax2.set_xticklabels(ga_df_net['name'], rotation=90, ha='right')\n",
    "            ax2.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "            ax2.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add legend to second plot\n",
    "            legend_elements = [Patch(facecolor=colors[cat], label=cat) for cat in colors.keys() if cat in ga_df_net['category'].values]\n",
    "            ax2.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nTop 5 by Convergence Speedup:\")\n",
    "        print(ga_df_sorted[['name', 'eval_savings_pct', 'convergence_iter']].head().to_string(index=False))\n",
    "        \n",
    "        if 'net_eval_savings_pct' in ga_df.columns:\n",
    "            print(\"\\nTop 5 by Net Evaluation Savings (accounting for GA overhead):\")\n",
    "            display_cols = ['name', 'net_eval_savings_pct', 'convergence_iter', 'dns_ga_total_evals']\n",
    "            available_cols = [col for col in display_cols if col in ga_df_net.columns]\n",
    "            print(ga_df_net[available_cols].head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05f711",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d35a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combined_df is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS BY CATEGORY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary = combined_df.groupby('category').agg({\n",
    "        'final_qd_score': ['mean', 'std', 'max'],\n",
    "        'final_max_fitness': ['mean', 'max'],\n",
    "        'final_coverage': ['mean', 'max']\n",
    "    }).round(2)\n",
    "    \n",
    "    print(summary)\n",
    "    \n",
    "    # Best overall\n",
    "    best = combined_df.loc[combined_df['final_qd_score'].idxmax()]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BEST OVERALL CONFIGURATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Name: {best['name']}\")\n",
    "    print(f\"Category: {best['category']}\")\n",
    "    print(f\"Final QD Score: {best['final_qd_score']:.2f}\")\n",
    "    print(f\"Max Fitness: {best['final_max_fitness']:.2f}\")\n",
    "    print(f\"Coverage: {best['final_coverage']:.2f}%\")\n",
    "    if 'eval_savings_pct' in best and pd.notna(best['eval_savings_pct']):\n",
    "        print(f\"Convergence Speedup: {best['eval_savings_pct']:.1f}%\")\n",
    "        if 'net_eval_savings_pct' in best and pd.notna(best['net_eval_savings_pct']):\n",
    "            print(f\"Net Evaluation Savings: {best['net_eval_savings_pct']:.1f}%\")\n",
    "        print(f\"Convergence Iteration: {best['convergence_iter']}\")\n",
    "    \n",
    "    # Best efficiency\n",
    "    if 'net_eval_savings_pct' in combined_df.columns:\n",
    "        ga_configs = combined_df[combined_df['net_eval_savings_pct'].notna()]\n",
    "        if len(ga_configs) > 0:\n",
    "            best_efficiency = ga_configs.loc[ga_configs['net_eval_savings_pct'].idxmax()]\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"MOST EFFICIENT CONFIGURATION (Net Savings)\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"Name: {best_efficiency['name']}\")\n",
    "            print(f\"Net Evaluation Savings: {best_efficiency['net_eval_savings_pct']:.1f}%\")\n",
    "            print(f\"Convergence Speedup: {best_efficiency['eval_savings_pct']:.1f}%\")\n",
    "            print(f\"Final QD Score: {best_efficiency['final_qd_score']:.2f}\")\n",
    "            if 'dns_ga_total_evals' in best_efficiency:\n",
    "                print(f\"Total Evaluations: {best_efficiency['dns_ga_total_evals']:,.0f} (vs {best_efficiency['baseline_total_evals']:,.0f} baseline)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90909e",
   "metadata": {},
   "source": [
    "## 9. Fair Comparison Analysis\n",
    "\n",
    "Key question: Does Competition-GA provide benefit beyond mutation tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combined_df is not None:\n",
    "    # Get baseline with different iso_sigma values\n",
    "    baseline_df = combined_df[combined_df['category'] == 'Baseline']\n",
    "    \n",
    "    if len(baseline_df) > 0:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FAIR COMPARISON ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nBaseline DNS Performance (different mutation strengths):\")\n",
    "        print(baseline_df[['name', 'final_qd_score']].to_string(index=False))\n",
    "        \n",
    "        # Find baseline with iso_sigma=0.01 (potentially best mutation)\n",
    "        baseline_01 = baseline_df[baseline_df['name'].str.contains('iso0.01')]\n",
    "        if len(baseline_01) > 0:\n",
    "            baseline_qd = baseline_01['final_qd_score'].values[0]\n",
    "            print(f\"\\nBest Baseline (iso=0.01): QD = {baseline_qd:.2f}\")\n",
    "            \n",
    "            # Compare with DNS-GA (all use iso=0.005)\n",
    "            ga_df = combined_df[(combined_df['category'] != 'Baseline') & \n",
    "                                (combined_df['category'] != 'Adaptive')]\n",
    "            \n",
    "            if len(ga_df) > 0:\n",
    "                best_ga = ga_df.loc[ga_df['final_qd_score'].idxmax()]\n",
    "                print(f\"\\nBest DNS-GA (iso=0.005): {best_ga['name']}\")\n",
    "                print(f\"  QD Score: {best_ga['final_qd_score']:.2f}\")\n",
    "                print(f\"  Improvement over baseline: {((best_ga['final_qd_score'] - baseline_qd) / baseline_qd * 100):.1f}%\")\n",
    "                \n",
    "                if best_ga['final_qd_score'] > baseline_qd:\n",
    "                    print(\"\\n✓ CONCLUSION: Competition-GA provides genuine benefit beyond mutation tuning!\")\n",
    "                else:\n",
    "                    print(\"\\n✗ CONCLUSION: Mutation tuning (iso=0.01) performs as well as Competition-GA\")\n",
    "    else:\n",
    "        print(\"\\nWaiting for baseline results to complete fair comparison analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a582539",
   "metadata": {},
   "source": [
    "## 10. Execution Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT EXECUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "experiments = [\n",
    "    ('Baselines', baseline_success, baseline_time),\n",
    "    ('Tier 1 - Proven Winners', tier1_success, tier1_time),\n",
    "    ('Tier 2 - Promising', tier2_success, tier2_time),\n",
    "    ('Tier 3 - Deep Foresight', tier3_success, tier3_time),\n",
    "    ('Tier 4 - Aggressive', tier4_success, tier4_time),\n",
    "    ('Tier 5 - Rare Deep', tier5_success, tier5_time),\n",
    "    ('Adaptive Experiments', adaptive_success, adaptive_time),\n",
    "]\n",
    "\n",
    "total_time = sum(t for _, _, t in experiments)\n",
    "success_count = sum(1 for _, s, _ in experiments if s)\n",
    "\n",
    "print(f\"\\n{'Experiment Suite':<30} {'Status':<10} {'Runtime'}\")\n",
    "print(\"-\" * 60)\n",
    "for name, success, runtime in experiments:\n",
    "    status = \"✓ SUCCESS\" if success else \"✗ FAILED\"\n",
    "    print(f\"{name:<30} {status:<10} {runtime/60:>6.1f} min\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'TOTAL':<30} {success_count}/{len(experiments):<10} {total_time/60:>6.1f} min\")\n",
    "print(f\"\\nTotal runtime: {total_time/3600:.2f} hours\")\n",
    "\n",
    "if combined_df is not None:\n",
    "    print(f\"\\nTotal experiments completed: {len(combined_df)}\")\n",
    "    print(f\"Results saved in: experiment_logs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b35145",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Review convergence plots** - Check individual CSV logs for detailed convergence behavior\n",
    "2. **Analyze evaluation savings** - Compare efficiency gains across configurations\n",
    "3. **Statistical significance** - Run multiple seeds for top performers\n",
    "4. **Publication** - Document findings for paper/report\n",
    "\n",
    "All experiment logs are saved in `experiment_logs/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
